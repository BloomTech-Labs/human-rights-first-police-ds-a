{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Sentence_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cacd9c3997654f38903f12bdefc1552b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7463430e3afd4e14acb6df4baa50450f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6621ada027a41c6996eadb38404ec1c",
              "IPY_MODEL_c1c2a04f0c24462ba54b11bc3a325160"
            ]
          }
        },
        "7463430e3afd4e14acb6df4baa50450f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6621ada027a41c6996eadb38404ec1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e1d7b0c4e694f4391a9fcb63ee3367f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04882f588a6746928e6f35cb252601b1"
          }
        },
        "c1c2a04f0c24462ba54b11bc3a325160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67832d7de12d47519eba5a1845acb764",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 94.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6268c5e31b4548d69c1e4aee2eb42d85"
          }
        },
        "2e1d7b0c4e694f4391a9fcb63ee3367f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04882f588a6746928e6f35cb252601b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67832d7de12d47519eba5a1845acb764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6268c5e31b4548d69c1e4aee2eb42d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "210ff64703904105b31a0bc64b67ea75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_86651521d39c4513869ec496dd07806f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5657dad1d2f4af586f66ab060fe16cb",
              "IPY_MODEL_f25e985af1044495b40d2d0aaf57eb43"
            ]
          }
        },
        "86651521d39c4513869ec496dd07806f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5657dad1d2f4af586f66ab060fe16cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8847a02152764ba8a2938830ac011d2c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2a472c6019b40818ae7d384b8ee7cd6"
          }
        },
        "f25e985af1044495b40d2d0aaf57eb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9913cf73cde64051b4d9dcc2801669f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 48.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36cffa70bd304c6489ce8b6dae255e3d"
          }
        },
        "8847a02152764ba8a2938830ac011d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2a472c6019b40818ae7d384b8ee7cd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9913cf73cde64051b4d9dcc2801669f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36cffa70bd304c6489ce8b6dae255e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5a04b5b7065436e83333bd2251cc8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a05a869f2bdb4011b65869c4b8aaa91f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ff1d9a1ed8d43928fab219e13f0338e",
              "IPY_MODEL_acd96682b33b46baa0dc7b4c9cd977bd"
            ]
          }
        },
        "a05a869f2bdb4011b65869c4b8aaa91f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ff1d9a1ed8d43928fab219e13f0338e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e741d4ef69cc49d0aad7ce4fe6c9c9c0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61569fe172cf409eb3827700494fb83b"
          }
        },
        "acd96682b33b46baa0dc7b4c9cd977bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f52ab9a28d1047aeb1c18a65638103b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a88b8a8ad874f1d94d3c6d7c0e4ab79"
          }
        },
        "e741d4ef69cc49d0aad7ce4fe6c9c9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61569fe172cf409eb3827700494fb83b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f52ab9a28d1047aeb1c18a65638103b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a88b8a8ad874f1d94d3c6d7c0e4ab79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a2369139f33411e95ecc517230712e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f831251bd984da29b684cab42ea10e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ba03c7ff57642d9a0ba822c1bc1a2d2",
              "IPY_MODEL_b3d4a2a5c9ae4dd0949a21877ae49a18"
            ]
          }
        },
        "0f831251bd984da29b684cab42ea10e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ba03c7ff57642d9a0ba822c1bc1a2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45e08af6abec4bdda8d6f6ccbf255d90",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d7debe730e14b0084b23acf48faec65"
          }
        },
        "b3d4a2a5c9ae4dd0949a21877ae49a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_642f07fe775d4978bd005f31cd7b0fd1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.32kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_819bafa0850142ef86c89e6995166e6f"
          }
        },
        "45e08af6abec4bdda8d6f6ccbf255d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d7debe730e14b0084b23acf48faec65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "642f07fe775d4978bd005f31cd7b0fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "819bafa0850142ef86c89e6995166e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e800677cbb2140cab4961a97c2ef740d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1903a26c20a24af5afdfefde84958490",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9656070ed53141d3a365819da63a3529",
              "IPY_MODEL_25b5603684b8453ca5a363d045bc43b7"
            ]
          }
        },
        "1903a26c20a24af5afdfefde84958490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9656070ed53141d3a365819da63a3529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ab52749dfe5420eb0a0a73c3592d17c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cac2d596dea94152987d420e43084f26"
          }
        },
        "25b5603684b8453ca5a363d045bc43b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a75c3de8110a4dbfa54a3382849960d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 56.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8b514676b8646f3ba0386dde1b15384"
          }
        },
        "4ab52749dfe5420eb0a0a73c3592d17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cac2d596dea94152987d420e43084f26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a75c3de8110a4dbfa54a3382849960d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8b514676b8646f3ba0386dde1b15384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL40uqmGcmxL"
      },
      "source": [
        "# Resources\n",
        "\n",
        "## Youtube:\n",
        "\n",
        "[BERT Research - Ep. 1 - Key Concepts & Sources](https://www.youtube.com/watch?v=FKlPCK1uFrc)  \n",
        "[BERT Research - Ep. 2 - WordPiece Embeddings](https://www.youtube.com/watch?v=zJW57aCBCTk)  \n",
        "[BERT Research - Ep. 3 - Fine Tuning - p.1](https://www.youtube.com/watch?v=x66kkDnbzi4)  \n",
        "[BERT Research - Ep. 3 - Fine Tuning - p.2](https://www.youtube.com/watch?v=Hnvb9b7a_Ps)\n",
        "\n",
        "\n",
        "## Jay Alammar:\n",
        "\n",
        "[Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)  \n",
        "[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)  \n",
        "[The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)\n",
        "\n",
        "## White Papers:\n",
        "\n",
        "[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)  \n",
        "[BERT](https://arxiv.org/pdf/1810.04805.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbh70rf1XYsK"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/bw_twitter_data.csv')\n",
        "\n",
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "df['clean_tweets'] = [re.sub('(?P<url>https?://[^\\s]+)', '', str(tweet)) for tweet in df['tweets']]\n",
        "df['clean_tweets'] = [re.sub('[^0-9 a-zA-Z@#]+', '', str(tweet)) for tweet in df['clean_tweets']]\n",
        "df['clean_tweets'] = [re.sub('@(.*?)[\\s]', '@user ', str(tweet)) for tweet in df['clean_tweets']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SkddVh-wZIGY",
        "outputId": "66a8387c-c2e6-4f29-b881-e0408c32dafd"
      },
      "source": [
        "df[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>tweets</th>\n",
              "      <th>clean_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A vote against the COVID-19 Hate Crimes Act is...</td>\n",
              "      <td>A vote against the COVID19 Hate Crimes Act is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@thehill @SenTedCruz @tedcruz You should just ...</td>\n",
              "      <td>@user @user @user You should just not ralk you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@Sites4Congress Police officers &amp;amp; public o...</td>\n",
              "      <td>@user Police officers amp public officials thr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Another Black Man Was Murder!!! Dropping tonig...</td>\n",
              "      <td>Another Black Man Was Murder Dropping tonight#...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@SonjatMorgan https://t.co/QcTEWrxMbP is a gra...</td>\n",
              "      <td>@user  is a grassroots movement to say thankyo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   labels  ...                                       clean_tweets\n",
              "0       0  ...  A vote against the COVID19 Hate Crimes Act is ...\n",
              "1       0  ...  @user @user @user You should just not ralk you...\n",
              "2       1  ...  @user Police officers amp public officials thr...\n",
              "3       1  ...  Another Black Man Was Murder Dropping tonight#...\n",
              "4       0  ...  @user  is a grassroots movement to say thankyo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IFAiR6BFGGF",
        "outputId": "e8becc90-8df1-4759-e5b5-c2d23ae8b746"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0g56Ci9mEJL",
        "outputId": "e19cd078-6d1c-4347-8dbd-4177eb9982c2"
      },
      "source": [
        "!pip install transformers wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 12.5MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=59e388dd164b7fc635ae23a511a1fa355505762fde90eb10a171e84ad85e9808\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, wget\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1 wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkJjRhStqeVA"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "HaNLJdxNpmyi",
        "outputId": "a8fed04c-c62e-47d2-a6cd-bcc55f5c29f6"
      },
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "# df = pd.read_csv('/content/bw_clean_tweets.csv')\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 51,218\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>tweets</th>\n",
              "      <th>clean_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50862</th>\n",
              "      <td>0</td>\n",
              "      <td>Week 16: Monday 04/19/21 11:50AM\\nTotal tests ...</td>\n",
              "      <td>Week 16 Monday 041921 1150AMTotal tests perfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16059</th>\n",
              "      <td>0</td>\n",
              "      <td>Visit the below link for any query related to ...</td>\n",
              "      <td>Visit the below link for any query related to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40579</th>\n",
              "      <td>0</td>\n",
              "      <td>Powerful Health Opportunity and Equity (HOPE) ...</td>\n",
              "      <td>Powerful Health Opportunity and Equity HOPE mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46942</th>\n",
              "      <td>1</td>\n",
              "      <td>Time to organize and help the protesters in #M...</td>\n",
              "      <td>Time to organize and help the protesters in #M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46789</th>\n",
              "      <td>1</td>\n",
              "      <td>@Bowden4Senate @RepDianaDeGette So you agree c...</td>\n",
              "      <td>@user @user So you agree civilians should be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11865</th>\n",
              "      <td>0</td>\n",
              "      <td>@mtgreenee @RepMaxineWaters No you should be e...</td>\n",
              "      <td>@user @user No you should be expelled from con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8541</th>\n",
              "      <td>0</td>\n",
              "      <td>New York allowing more fans inside sports aren...</td>\n",
              "      <td>New York allowing more fans inside sports aren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23083</th>\n",
              "      <td>1</td>\n",
              "      <td>@j321614 We are seeking the public's assistanc...</td>\n",
              "      <td>@user We are seeking the publics assistance re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35393</th>\n",
              "      <td>0</td>\n",
              "      <td>@Yamiere1 @talkRADIO @Iromg @ClarkeMicah Or wh...</td>\n",
              "      <td>@user @user @user @user Or what does Donald Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7804</th>\n",
              "      <td>1</td>\n",
              "      <td>I feel like a civil war is coming BLM vs white...</td>\n",
              "      <td>I feel like a civil war is coming BLM vs white...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       labels  ...                                       clean_tweets\n",
              "50862       0  ...  Week 16 Monday 041921 1150AMTotal tests perfor...\n",
              "16059       0  ...  Visit the below link for any query related to ...\n",
              "40579       0  ...  Powerful Health Opportunity and Equity HOPE mi...\n",
              "46942       1  ...  Time to organize and help the protesters in #M...\n",
              "46789       1  ...  @user @user So you agree civilians should be a...\n",
              "11865       0  ...  @user @user No you should be expelled from con...\n",
              "8541        0  ...  New York allowing more fans inside sports aren...\n",
              "23083       1  ...  @user We are seeking the publics assistance re...\n",
              "35393       0  ...  @user @user @user @user Or what does Donald Tr...\n",
              "7804        1  ...  I feel like a civil war is coming BLM vs white...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7mmGeVvqLtj"
      },
      "source": [
        "sentences = df.clean_tweets.values\n",
        "labels = df.labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnx60mwMqgvo"
      },
      "source": [
        "# Tokenization & Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCzMdj3hqcwz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "cacd9c3997654f38903f12bdefc1552b",
            "7463430e3afd4e14acb6df4baa50450f",
            "c6621ada027a41c6996eadb38404ec1c",
            "c1c2a04f0c24462ba54b11bc3a325160",
            "2e1d7b0c4e694f4391a9fcb63ee3367f",
            "04882f588a6746928e6f35cb252601b1",
            "67832d7de12d47519eba5a1845acb764",
            "6268c5e31b4548d69c1e4aee2eb42d85",
            "210ff64703904105b31a0bc64b67ea75",
            "86651521d39c4513869ec496dd07806f",
            "c5657dad1d2f4af586f66ab060fe16cb",
            "f25e985af1044495b40d2d0aaf57eb43",
            "8847a02152764ba8a2938830ac011d2c",
            "b2a472c6019b40818ae7d384b8ee7cd6",
            "9913cf73cde64051b4d9dcc2801669f9",
            "36cffa70bd304c6489ce8b6dae255e3d",
            "a5a04b5b7065436e83333bd2251cc8d4",
            "a05a869f2bdb4011b65869c4b8aaa91f",
            "7ff1d9a1ed8d43928fab219e13f0338e",
            "acd96682b33b46baa0dc7b4c9cd977bd",
            "e741d4ef69cc49d0aad7ce4fe6c9c9c0",
            "61569fe172cf409eb3827700494fb83b",
            "f52ab9a28d1047aeb1c18a65638103b2",
            "2a88b8a8ad874f1d94d3c6d7c0e4ab79"
          ]
        },
        "outputId": "259f20aa-f282-43b5-d506-bcc386543f1c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cacd9c3997654f38903f12bdefc1552b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "210ff64703904105b31a0bc64b67ea75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5a04b5b7065436e83333bd2251cc8d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjHD1ZT_r7jk"
      },
      "source": [
        "## Sentences to IDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdoKgnycq2ui",
        "outputId": "52be8f4c-011a-4452-d9d7-e0089220ed08"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  A vote against the COVID19 Hate Crimes Act is a vote to retain the status quo of treating Asian Americans as secon \n",
            "Token IDs: [101, 1037, 3789, 2114, 1996, 2522, 17258, 16147, 5223, 6997, 2552, 2003, 1037, 3789, 2000, 9279, 1996, 3570, 22035, 1997, 12318, 4004, 4841, 2004, 10819, 2239, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8REaXKJLr_e2"
      },
      "source": [
        "# Padding and Truncating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQyPWsTssE80",
        "outputId": "da31fd89-41b9-41f7-941f-cedd8a4e136d"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM5U6lSWs1t6"
      },
      "source": [
        "# Attention Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itxv02Gssqna"
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD0i93qJtbd4"
      },
      "source": [
        "# Train/Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDKHjaRVtXQp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=42, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=42, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbhVCMQzuTii"
      },
      "source": [
        "## Convert to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwT4tGwvuHfl"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po0eZ3ZYu3ul"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaNjnkvPwbf7"
      },
      "source": [
        "# BERT for Sequence Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a2369139f33411e95ecc517230712e5",
            "0f831251bd984da29b684cab42ea10e3",
            "1ba03c7ff57642d9a0ba822c1bc1a2d2",
            "b3d4a2a5c9ae4dd0949a21877ae49a18",
            "45e08af6abec4bdda8d6f6ccbf255d90",
            "2d7debe730e14b0084b23acf48faec65",
            "642f07fe775d4978bd005f31cd7b0fd1",
            "819bafa0850142ef86c89e6995166e6f",
            "e800677cbb2140cab4961a97c2ef740d",
            "1903a26c20a24af5afdfefde84958490",
            "9656070ed53141d3a365819da63a3529",
            "25b5603684b8453ca5a363d045bc43b7",
            "4ab52749dfe5420eb0a0a73c3592d17c",
            "cac2d596dea94152987d420e43084f26",
            "a75c3de8110a4dbfa54a3382849960d7",
            "a8b514676b8646f3ba0386dde1b15384"
          ]
        },
        "id": "Fl65EoShv1m1",
        "outputId": "26600826-a0e5-4167-837e-b64bf4d03c4a"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels=2,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a2369139f33411e95ecc517230712e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e800677cbb2140cab4961a97c2ef740d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOmE7oye5kSO"
      },
      "source": [
        "# Optimizer and Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d3pu39-5Hmy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8)\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# learning rate scheduler (handles weight decay)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnXpjYrh7Ebk"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOAKKGms52eq"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uClUsHwY7vwd"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKBVs0wQ8Iyl",
        "outputId": "ec01f091-80af-408d-dece-b015de4d7915"
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,441.    Elapsed: 0:00:05.\n",
            "  Batch    80  of  1,441.    Elapsed: 0:00:10.\n",
            "  Batch   120  of  1,441.    Elapsed: 0:00:15.\n",
            "  Batch   160  of  1,441.    Elapsed: 0:00:20.\n",
            "  Batch   200  of  1,441.    Elapsed: 0:00:25.\n",
            "  Batch   240  of  1,441.    Elapsed: 0:00:31.\n",
            "  Batch   280  of  1,441.    Elapsed: 0:00:36.\n",
            "  Batch   320  of  1,441.    Elapsed: 0:00:41.\n",
            "  Batch   360  of  1,441.    Elapsed: 0:00:46.\n",
            "  Batch   400  of  1,441.    Elapsed: 0:00:51.\n",
            "  Batch   440  of  1,441.    Elapsed: 0:00:56.\n",
            "  Batch   480  of  1,441.    Elapsed: 0:01:01.\n",
            "  Batch   520  of  1,441.    Elapsed: 0:01:06.\n",
            "  Batch   560  of  1,441.    Elapsed: 0:01:11.\n",
            "  Batch   600  of  1,441.    Elapsed: 0:01:16.\n",
            "  Batch   640  of  1,441.    Elapsed: 0:01:21.\n",
            "  Batch   680  of  1,441.    Elapsed: 0:01:26.\n",
            "  Batch   720  of  1,441.    Elapsed: 0:01:32.\n",
            "  Batch   760  of  1,441.    Elapsed: 0:01:37.\n",
            "  Batch   800  of  1,441.    Elapsed: 0:01:42.\n",
            "  Batch   840  of  1,441.    Elapsed: 0:01:47.\n",
            "  Batch   880  of  1,441.    Elapsed: 0:01:52.\n",
            "  Batch   920  of  1,441.    Elapsed: 0:01:57.\n",
            "  Batch   960  of  1,441.    Elapsed: 0:02:02.\n",
            "  Batch 1,000  of  1,441.    Elapsed: 0:02:07.\n",
            "  Batch 1,040  of  1,441.    Elapsed: 0:02:12.\n",
            "  Batch 1,080  of  1,441.    Elapsed: 0:02:17.\n",
            "  Batch 1,120  of  1,441.    Elapsed: 0:02:22.\n",
            "  Batch 1,160  of  1,441.    Elapsed: 0:02:27.\n",
            "  Batch 1,200  of  1,441.    Elapsed: 0:02:33.\n",
            "  Batch 1,240  of  1,441.    Elapsed: 0:02:38.\n",
            "  Batch 1,280  of  1,441.    Elapsed: 0:02:43.\n",
            "  Batch 1,320  of  1,441.    Elapsed: 0:02:48.\n",
            "  Batch 1,360  of  1,441.    Elapsed: 0:02:53.\n",
            "  Batch 1,400  of  1,441.    Elapsed: 0:02:58.\n",
            "  Batch 1,440  of  1,441.    Elapsed: 0:03:03.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:03:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,441.    Elapsed: 0:00:05.\n",
            "  Batch    80  of  1,441.    Elapsed: 0:00:10.\n",
            "  Batch   120  of  1,441.    Elapsed: 0:00:15.\n",
            "  Batch   160  of  1,441.    Elapsed: 0:00:20.\n",
            "  Batch   200  of  1,441.    Elapsed: 0:00:26.\n",
            "  Batch   240  of  1,441.    Elapsed: 0:00:31.\n",
            "  Batch   280  of  1,441.    Elapsed: 0:00:36.\n",
            "  Batch   320  of  1,441.    Elapsed: 0:00:41.\n",
            "  Batch   360  of  1,441.    Elapsed: 0:00:46.\n",
            "  Batch   400  of  1,441.    Elapsed: 0:00:51.\n",
            "  Batch   440  of  1,441.    Elapsed: 0:00:56.\n",
            "  Batch   480  of  1,441.    Elapsed: 0:01:01.\n",
            "  Batch   520  of  1,441.    Elapsed: 0:01:06.\n",
            "  Batch   560  of  1,441.    Elapsed: 0:01:11.\n",
            "  Batch   600  of  1,441.    Elapsed: 0:01:17.\n",
            "  Batch   640  of  1,441.    Elapsed: 0:01:22.\n",
            "  Batch   680  of  1,441.    Elapsed: 0:01:27.\n",
            "  Batch   720  of  1,441.    Elapsed: 0:01:32.\n",
            "  Batch   760  of  1,441.    Elapsed: 0:01:37.\n",
            "  Batch   800  of  1,441.    Elapsed: 0:01:42.\n",
            "  Batch   840  of  1,441.    Elapsed: 0:01:47.\n",
            "  Batch   880  of  1,441.    Elapsed: 0:01:52.\n",
            "  Batch   920  of  1,441.    Elapsed: 0:01:57.\n",
            "  Batch   960  of  1,441.    Elapsed: 0:02:02.\n",
            "  Batch 1,000  of  1,441.    Elapsed: 0:02:07.\n",
            "  Batch 1,040  of  1,441.    Elapsed: 0:02:12.\n",
            "  Batch 1,080  of  1,441.    Elapsed: 0:02:18.\n",
            "  Batch 1,120  of  1,441.    Elapsed: 0:02:23.\n",
            "  Batch 1,160  of  1,441.    Elapsed: 0:02:28.\n",
            "  Batch 1,200  of  1,441.    Elapsed: 0:02:33.\n",
            "  Batch 1,240  of  1,441.    Elapsed: 0:02:38.\n",
            "  Batch 1,280  of  1,441.    Elapsed: 0:02:43.\n",
            "  Batch 1,320  of  1,441.    Elapsed: 0:02:48.\n",
            "  Batch 1,360  of  1,441.    Elapsed: 0:02:53.\n",
            "  Batch 1,400  of  1,441.    Elapsed: 0:02:58.\n",
            "  Batch 1,440  of  1,441.    Elapsed: 0:03:03.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:03:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,441.    Elapsed: 0:00:05.\n",
            "  Batch    80  of  1,441.    Elapsed: 0:00:10.\n",
            "  Batch   120  of  1,441.    Elapsed: 0:00:15.\n",
            "  Batch   160  of  1,441.    Elapsed: 0:00:20.\n",
            "  Batch   200  of  1,441.    Elapsed: 0:00:25.\n",
            "  Batch   240  of  1,441.    Elapsed: 0:00:30.\n",
            "  Batch   280  of  1,441.    Elapsed: 0:00:36.\n",
            "  Batch   320  of  1,441.    Elapsed: 0:00:41.\n",
            "  Batch   360  of  1,441.    Elapsed: 0:00:46.\n",
            "  Batch   400  of  1,441.    Elapsed: 0:00:51.\n",
            "  Batch   440  of  1,441.    Elapsed: 0:00:56.\n",
            "  Batch   480  of  1,441.    Elapsed: 0:01:01.\n",
            "  Batch   520  of  1,441.    Elapsed: 0:01:06.\n",
            "  Batch   560  of  1,441.    Elapsed: 0:01:11.\n",
            "  Batch   600  of  1,441.    Elapsed: 0:01:16.\n",
            "  Batch   640  of  1,441.    Elapsed: 0:01:21.\n",
            "  Batch   680  of  1,441.    Elapsed: 0:01:26.\n",
            "  Batch   720  of  1,441.    Elapsed: 0:01:31.\n",
            "  Batch   760  of  1,441.    Elapsed: 0:01:36.\n",
            "  Batch   800  of  1,441.    Elapsed: 0:01:41.\n",
            "  Batch   840  of  1,441.    Elapsed: 0:01:46.\n",
            "  Batch   880  of  1,441.    Elapsed: 0:01:52.\n",
            "  Batch   920  of  1,441.    Elapsed: 0:01:57.\n",
            "  Batch   960  of  1,441.    Elapsed: 0:02:02.\n",
            "  Batch 1,000  of  1,441.    Elapsed: 0:02:07.\n",
            "  Batch 1,040  of  1,441.    Elapsed: 0:02:12.\n",
            "  Batch 1,080  of  1,441.    Elapsed: 0:02:17.\n",
            "  Batch 1,120  of  1,441.    Elapsed: 0:02:22.\n",
            "  Batch 1,160  of  1,441.    Elapsed: 0:02:27.\n",
            "  Batch 1,200  of  1,441.    Elapsed: 0:02:32.\n",
            "  Batch 1,240  of  1,441.    Elapsed: 0:02:37.\n",
            "  Batch 1,280  of  1,441.    Elapsed: 0:02:42.\n",
            "  Batch 1,320  of  1,441.    Elapsed: 0:02:47.\n",
            "  Batch 1,360  of  1,441.    Elapsed: 0:02:52.\n",
            "  Batch 1,400  of  1,441.    Elapsed: 0:02:57.\n",
            "  Batch 1,440  of  1,441.    Elapsed: 0:03:02.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:03:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,441.    Elapsed: 0:00:05.\n",
            "  Batch    80  of  1,441.    Elapsed: 0:00:10.\n",
            "  Batch   120  of  1,441.    Elapsed: 0:00:15.\n",
            "  Batch   160  of  1,441.    Elapsed: 0:00:20.\n",
            "  Batch   200  of  1,441.    Elapsed: 0:00:25.\n",
            "  Batch   240  of  1,441.    Elapsed: 0:00:30.\n",
            "  Batch   280  of  1,441.    Elapsed: 0:00:35.\n",
            "  Batch   320  of  1,441.    Elapsed: 0:00:40.\n",
            "  Batch   360  of  1,441.    Elapsed: 0:00:45.\n",
            "  Batch   400  of  1,441.    Elapsed: 0:00:50.\n",
            "  Batch   440  of  1,441.    Elapsed: 0:00:56.\n",
            "  Batch   480  of  1,441.    Elapsed: 0:01:01.\n",
            "  Batch   520  of  1,441.    Elapsed: 0:01:06.\n",
            "  Batch   560  of  1,441.    Elapsed: 0:01:11.\n",
            "  Batch   600  of  1,441.    Elapsed: 0:01:16.\n",
            "  Batch   640  of  1,441.    Elapsed: 0:01:21.\n",
            "  Batch   680  of  1,441.    Elapsed: 0:01:26.\n",
            "  Batch   720  of  1,441.    Elapsed: 0:01:31.\n",
            "  Batch   760  of  1,441.    Elapsed: 0:01:36.\n",
            "  Batch   800  of  1,441.    Elapsed: 0:01:41.\n",
            "  Batch   840  of  1,441.    Elapsed: 0:01:46.\n",
            "  Batch   880  of  1,441.    Elapsed: 0:01:51.\n",
            "  Batch   920  of  1,441.    Elapsed: 0:01:56.\n",
            "  Batch   960  of  1,441.    Elapsed: 0:02:01.\n",
            "  Batch 1,000  of  1,441.    Elapsed: 0:02:06.\n",
            "  Batch 1,040  of  1,441.    Elapsed: 0:02:11.\n",
            "  Batch 1,080  of  1,441.    Elapsed: 0:02:16.\n",
            "  Batch 1,120  of  1,441.    Elapsed: 0:02:21.\n",
            "  Batch 1,160  of  1,441.    Elapsed: 0:02:26.\n",
            "  Batch 1,200  of  1,441.    Elapsed: 0:02:31.\n",
            "  Batch 1,240  of  1,441.    Elapsed: 0:02:36.\n",
            "  Batch 1,280  of  1,441.    Elapsed: 0:02:41.\n",
            "  Batch 1,320  of  1,441.    Elapsed: 0:02:46.\n",
            "  Batch 1,360  of  1,441.    Elapsed: 0:02:51.\n",
            "  Batch 1,400  of  1,441.    Elapsed: 0:02:56.\n",
            "  Batch 1,440  of  1,441.    Elapsed: 0:03:02.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:03:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2JJiIENNEb-"
      },
      "source": [
        "# Evaluate and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "QvLndIgB91FP",
        "outputId": "fc66dcf0-a018-4bd5-f449-ba59b0745bb3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVxWdfr/8dd9swrIDiqrKAqKomxuWRoumanlVlppauM4Td+Z1pl0rFFrqm9lkzbfcfpZ7qPlEsZkZimZbSaCKC64ISmLC64Iyib8/jCZSFyQ5dzI+/nPPO5z3+ecC6+B3hw+5zqm8vLyckREREREpEEwG12AiIiIiIjcPAV4EREREZEGRAFeRERERKQBUYAXEREREWlAFOBFRERERBoQBXgRERERkQZEAV5EpJHJysoiJCSEf/zjH7d8jMmTJxMSElKLVd2akJAQJk+ebHQZIiL1ytroAkREGrvqBOGEhAT8/PzqsBoREbF0Jj3ISUTEWPHx8ZVeJycns3z5ch566CGioqIqvdevXz8cHBxqdL7y8nKKi4uxsrLC2vrWruOUlJRQVlaGnZ1djWqpqZCQEIYOHcr//u//GlqHiEh90hV4ERGD3X///ZVeX7p0ieXLl9O5c+er3vu1/Px8nJycqnU+k8lU4+BtY2NTo/1FROTWaQ28iEgDERsby5gxY9izZw+PP/44UVFRDBkyBLgc5N955x1GjhxJ165d6dChA/369WPmzJlcvHix0nGqWgP/y20bN25k+PDhdOzYkZ49e/LGG29QWlpa6RhVrYG/su38+fNMmzaN7t2707FjR0aNGsWOHTuu+nrOnDnDlClT6Nq1KxEREYwdO5Y9e/YwZswYYmNja/RvtXLlSoYOHUp4eDhRUVFMmDCBpKSkqz739ddf8+ijj9K1a1fCw8Pp3bs3//M//0NGRkbFZ44ePcqUKVO4++676dChA927d2fUqFGsXr26RjWKiNwqXYEXEWlAcnJyeOyxxxgwYAD9+/fnwoULABw/fpxVq1bRv39/Bg0ahLW1NYmJiXzwwQekpaUxb968mzr+pk2bWLZsGaNGjWL48OEkJCQwf/58XFxc+N3vfndTx3j88cdxd3fnySef5OzZsyxYsIDf/va3JCQkVPy1oLi4mPHjx5OWlsawYcPo2LEj+/btY/z48bi4uNzaP87P3nrrLT744APCw8N59tlnyc/PZ8WKFTz22GPMmTOHXr16AZCYmMgTTzxBmzZtmDRpEk2bNuXEiRNs3ryZI0eOEBQURGlpKePHj+f48eM8/PDDtGzZkvz8fPbt20dSUhJDhw6tUa0iIrdCAV5EpAHJysrib3/7GyNHjqy03d/fn6+//rrS0pZHHnmEWbNm8a9//YvU1FTCw8NvePyDBw+yZs2aihtlR48ezeDBg/n3v/990wG+ffv2TJ8+veJ169atefrpp1mzZg2jRo0CLl8hT0tL4+mnn+aJJ56o+Gzbtm15+eWX8fX1valz/dqhQ4eYN28ekZGRLFq0CFtbWwBGjhzJfffdx4wZM1i/fj1WVlYkJCRQVlbGggUL8PDwqDjGk08+WenfIyMjg+eff56JEyfeUk0iIrVNS2hERBoQV1dXhg0bdtV2W1vbivBeWlrKuXPnOH36ND169ACocglLVfr06VNpyo3JZKJr167k5uZSUFBwU8cYN25cpdfdunUD4PDhwxXbNm7ciJWVFWPHjq302ZEjR9K0adObOk9VEhISKC8v5ze/+U1FeAdo1qwZw4YNIzs7mz179gBUnOeLL764aonQFVc+s2XLFk6dOnXLdYmI1CZdgRcRaUD8/f2xsrKq8r2lS5fy0UcfcfDgQcrKyiq9d+7cuZs+/q+5uroCcPbsWRwdHat9DDc3t4r9r8jKysLb2/uq49na2uLn50deXt5N1ftrWVlZALRp0+aq965sy8zMpGPHjjzyyCMkJCQwY8YMZs6cSVRUFHfeeSeDBg3C3d0dAF9fX373u98xd+5cevbsSbt27ejWrRsDBgy4qb9oiIjUBV2BFxFpQJo0aVLl9gULFvDyyy/j7e3Nyy+/zNy5c1mwYEHFeMWbnRh8rV8OauMYlja12M3NjVWrVrF48WLGjBlDQUEBr7/+Ovfccw8pKSkVn3vmmWf48ssv+ctf/oK/vz+rVq1i5MiRvPXWWwZWLyKNma7Ai4jcBuLj4/H19eX999/HbP7vtZlvvvnGwKquzdfXl82bN1NQUFDpKnxJSQlZWVk4Ozvf0nGvXP0/cOAAAQEBld47ePBgpc/A5V82unbtSteuXQHYu3cvw4cP51//+hdz586tdNwxY8YwZswYioqKePzxx/nggw+YMGFCpfXzIiL1QVfgRURuA2azGZPJVOkqd2lpKe+//76BVV1bbGwsly5dYvHixZW2r1ixgvPnz9fouCaTiXnz5lFSUlKx/cSJE8TFxeHr60v79u0BOH369FX7t2rVCjs7u4olR+fPn690HAA7OztatWoF3PzSJBGR2qQr8CIit4EBAwbw9ttvM3HiRPr160d+fj5r1qy55Set1rWRI0fy0UcfMWvWLI4cOVIxRnLdunUEBgZe86bSG2nVqlXF1fFHH32Ue++9l4KCAlasWMGFCxeYOXNmxRKfl156iWPHjtGzZ098fHwoLCzk888/p6CgoOIBWlu2bOGll16if//+BAUF4ejoyK5du1i1ahWdOnWqCPIiIvXJMn+yi4hItTz++OOUl5ezatUqXn31Vby8vLj33nsZPnw4AwcONLq8q9ja2rJo0SLefPNNEhIS+PzzzwkPD2fhwoVMnTqVwsLCWz72n/70JwIDA1m2bBlvv/02NjY2dOrUibfffpvo6OiKz91///3ExcWxevVqTp8+jZOTE8HBwbz77rvcc889AISEhNCvXz8SExP59NNPKSsro0WLFkyaNIkJEybU+N9BRORWmMot7a4iERFptC5dukS3bt0IDw+/6YdPiYg0NloDLyIihqjqKvtHH31EXl4ed9xxhwEViYg0DFpCIyIihnjxxRcpLi4mIiICW1tbUlJSWLNmDYGBgTz44INGlyciYrG0hEZERAzxySefsHTpUn766ScuXLiAh4cHvXr14qmnnsLT09Po8kRELJYCvIiIiIhIA6I18CIiIiIiDYgCvIiIiIhIA6KbWKvpzJkCysrqf9WRh4cTp07l1/t55drUE8ukvlge9cQyqS+WRz2xTEb0xWw24ebmeM33FeCrqays3JAAf+XcYlnUE8ukvlge9cQyqS+WRz2xTJbWFy2hERERERFpQBTgRUREREQaEAV4EREREZEGRAFeRERERKQBUYAXEREREWlAFOBFRERERBoQBXgRERERkQZEAV5EREREpAFRgBcRERERaUD0JFYLt3n3MeI2pXM6rwh3ZzuG9WpN97DmRpclIiIiIgYxPMAXFxcze/Zs4uPjycvLIzQ0lGeeeYbu3btfd7/U1FTi4uJITU1l//79lJSUsG/fvmt+PiMjg9mzZ/Pjjz9y4cIFfH19GTZsGBMnTqztL6nWbN59jEWf76W4tAyAU3lFLPp8L4BCvIiIiEgjZfgSmsmTJ7No0SKGDBnC1KlTMZvNTJw4kZSUlOvut2nTJlauXAmAv7//dT+7e/duRowYQXZ2NpMmTeLFF1+kb9++HDt2rNa+jroQtym9IrxfUVxaRtymdIMqEhERERGjGXoFPjU1lc8++4wpU6Ywbtw4AB544AEGDRrEzJkzWbp06TX3HT16NBMnTsTe3p5XX32VQ4cOVfm5S5cu8ec//5nu3bvz7rvvYjYb/jvLTTuVV1St7SIiIiJy+zM0za5btw4bGxtGjhxZsc3Ozo4RI0aQnJzMiRMnrrmvp6cn9vb2NzzHd999x8GDB3nmmWcwm80UFBRQVlZ2w/0sgYezXZXbnZrY1HMlIiIiImIpDA3waWlpBAUF4ejoWGl7eHg45eXlpKWl1fgcmzdvxsnJiePHj3PPPfcQGRlJZGQkL774IhcvXqzx8evSsF6tsbWu3CITkH+xhCVf7KO45JIxhYmIiIiIYQxdQpObm0uzZs2u2u7l5QVw3SvwN+vw4cNcunSJ3//+9wwfPpznnnuOlJQUFixYwOnTp5kzZ06Nz1FXrtyo+sspNA/c2Yrs3ALWJR7hQNZZJt3fAV9PxxscSURERERuF4YG+MLCQmxsrl4OYmd3eelIUVHN13pfuHCBixcvMmrUKF566SUA+vfvj8lkYt68eezdu5fQ0NCbPp6Hh1ONa6qOIb2bMqR3m6u2dw33YdZH23hlURK/faAj/bsGYDKZ6rU2AS+vpkaXIFVQXyyPemKZ1BfLo55YJkvri6EB3t7enpKSkqu2XwnuV4J8Tc8BMGjQoErbhwwZwrx580hOTq5WgD91Kp+ysvIa11VdXl5Nyc09X/E60NOBaeNieP/TPfzfyu0k7sph7D2hONgbPhm00fh1T8QyqC+WRz2xTOqL5VFPLJMRfTGbTde9aGzoGngvL68ql8nk5uYC4O3tXSvnAPDw8Ki0/crrvLy8Gp/DKK5Odjz3UGeG92pF0t5cpi9IJD3nnNFliYiIiEgdMjTAh4aGkpGRQUFBQaXtO3bsqHi/psLCwgA4fvx4pe1XZsC7u7vX+BxGMptN3Ne9JZMfiaS8HP7339v4/MfDlJXX/18JRERERKTuGRrgBwwYQElJScUDmeDyk1nj4uKIjIysuME1JyeH9PRbe3hRbGwsNjY2rFq1qtL2lStXYjKZ6Nat261/ARYk2M+FGRNi6NzGk5Vfp/POih2cKyg2uiwRERERqWWGLpju1KkTAwYMYObMmeTm5hIQEMDq1avJycnh9ddfr/jcCy+8QGJiIvv27avYlp2dTXx8PAA7d+4EqJgoExoaSmxsLADNmjXjt7/9Lf/85z8pKSmhW7dupKSk8J///IeHH36YwMDA+vpy65yDvQ2/f6ADm7bn8GHCAabNT2TioPaEBTXsvzKIiIiIyH8Zfsfjm2++yaxZs4iPj+fcuXOEhIQwd+5coqKirrtfVlYWs2fPrrTtyuuhQ4dWBHiAP/zhDzg7O7Ns2TK++uorvL29efrpp5k0aVLtf0EGM5lM9I7wJdjPhffid/P28u3c2y2AoXe2wtqq4TyFVkRERESqZiov12Lp6rCUKTQ3o6jkEh8lHGDT9hxa+TgzaUgYXq5N6qjCxkfTAiyT+mJ51BPLpL5YHvXEMmkKjdQrOxsrHhsQyhMPdODoqQKmL0gkMe34jXcUEREREYulAN8IxIR6M318F1p4OPJe/G4Wfr6XopJLRpclIiIiIrdAAb6R8HJtwuRHIhnYLZBvd+TwyqIksnLzjS5LRERERKpJAb4RsbYyM6J3a559qDP5F0t4ZVESX6dko9sgRERERBoOBfhGKCzInRkTutDW35XFX+xjzie7KCgsMbosEREREbkJCvCNlIujLc882ImRd7dm+4GTTJ+fyMGsc0aXJSIiIiI3oADfiJlNJu7tGsjkRyMxmUz879JtrPnhJ0PGZIqIiIjIzVGAF1r7uDB9fBeiQ72I++YQby/fztn8IqPLEhEREZEqKMALAA721kwaEsa4e0NJzz7HtPmJpKafMrosEREREfkVBXipYDKZuKuTDy+Ni8HF0ZZZK3ew/KsDlF4qM7o0EREREfmZArxcxdfTkRfHRnN3hC9fJGby2pJkTpy5YHRZIiIiIoICvFyDrY0VY+4J4cmhHThx5iLTF2zlxz3HjC5LREREpNFTgJfrigrxZvqEGPy8nJj7nz3M/yyNouJLRpclIiIi0mgpwMsNebo04YVHIhjUI5Dvdx5lxsKtHDl+3uiyRERERBolBXi5KVZmM8Puas3zozpzsbiUvy1OJiE5i/JyzYwXERERqU8K8FIt7Vq6M2NCF9q3dGPp+v38X9xO8i+WGF2WiIiISKOhAC/V5uxgyx9HhDMqNpjU9FNMX5DI/syzRpclIiIi0igowMstMZtM9O8SwF/GRGFtNvPGsm385/sMysq0pEZERESkLinAS40EtXBm2vgYurZrxiffZjDzoxTOnC8yuiwRERGR25YCvNRYEztrJg5uz4SB7Th0NI9p8xPZfvCk0WWJiIiI3JYU4KVWmEwmeoa3YNq4GNyb2vHuqlSWbdhPSWmZ0aWJiIiI3FYU4KVWtfBwZOrYKPpE+bEhKYtXlyRx7PQFo8sSERERuW0owEuts7G24pF+bfnDsI6cOlfIjAVb+WHXUaPLEhEREbktKMBLnYlo68WMCV0IbObEB2vSeP/TPVwsKjW6LBEREZEGTQFe6pS7sz1/ejiCIXe05Mc9x3h54VYOHztvdFkiIiIiDZYCvNQ5K7OZB+5sxZ9HR1BcWsarS5JYvzWT8nLNjBcRERGpLgV4qTchAW5MHx9DhyAPPkw4wLurUjl/odjoskREREQaFAV4qVdNHWz5w/COjO7bht0/nWba/ET2Hj5jdFkiIiIiDYYCvNQ7k8lEv2h/po6Jxs7Girc+TGH1N4e4VKaZ8SIiIiI3ogAvhgls3pRp42Po0aE5n/7wE28uS+F0XqHRZYmIiIhYNAV4MZS9rTWPD2rPxEHtOXIin2nzE0nZn2t0WSIiIiIWSwFeLEL3Ds2ZPi4GT5cm/CNuJ0u/3E9J6SWjyxIRERGxOArwYjGauTvwlzFR9I/xJ2FbFn9bnMzRUwVGlyUiIiJiUQwN8MXFxbz11lv07NmT8PBwHnzwQTZv3nzD/VJTU5k+fTrDhg2jQ4cOhISE3NT51q5dS0hICNHR0TUtXeqIjbWZUX3a8NSIcM6cL2LGwq18m5qjmfEiIiIiPzM0wE+ePJlFixYxZMgQpk6ditlsZuLEiaSkpFx3v02bNrFy5UoA/P39b+pchYWFvPXWWzg4ONS4bql7nYI9mTGhC61aOLNg7V7e/3QPF4tKjS5LRERExHCGBfjU1FQ+++wznn/+ef785z/z0EMPsWjRIlq0aMHMmTOvu+/o0aNJTk4mLi6Onj173tT53n//fWxtbYmNja2N8qUeuDW14/lREQy9M4gtaceZsWArGUfzjC5LRERExFCGBfh169ZhY2PDyJEjK7bZ2dkxYsQIkpOTOXHixDX39fT0xN7e/qbPlZOTwwcffMALL7yAjY1NjeqW+mU2mxh8RxAvPBxJaVkZry1JZt2WI5RpSY2IiIg0UoYF+LS0NIKCgnB0dKy0PTw8nPLyctLS0mrtXG+88QYRERG6+t6AtfV3Zfr4LnQK9mTFxoPMWrmDvIJio8sSERERqXeGBfjc3Fy8vb2v2u7l5QVw3Svw1ZGYmMj69euZPHlyrRxPjOPUxIYnh3bg0f5t2Xv4LNPmJ7Lnp9NGlyUiIiJSr6yNOnFhYWGVy1ns7OwAKCoqqvE5Ll26xN/+9jeGDRtGaGhojY8H4OHhVCvHuRVeXk0NO7cleegeZ7p09OHNJUm8vXw7I2Lb8PA9oVhb1f/vo+qJZVJfLI96YpnUF8ujnlgmS+uLYQHe3t6ekpKSq7ZfCe5XgnxNLF++nKysLObPn1/jY11x6lQ+ZWX1v/7ay6spubnn6/28lsrJxszUR6NYtmE/KxMOsG3vcSYNCcPTpUm91aCeWCb1xfKoJ5ZJfbE86ollMqIvZrPpuheNDVtC4+XlVeUymdzcXIAql9dUR3FxMe+++y7Dhg2jsLCQrKwssrKyuHDhAmVlZWRlZXH6tJZfNGR2tlaMH9iOSUPCyM4tYPr8rSTtrZ2lVyIiIiKWyrAr8KGhoSxZsoSCgoJKN7Lu2LGj4v2aKCws5MyZMyxZsoQlS5Zc9X6fPn0YOHAg77zzTo3OI8br2r4ZQS2a8v/+s5s5n+yid4Qvo2KDsbWxMro0ERERkVpnWIAfMGAA8+fPZ+XKlYwbNw64fNU8Li6OyMhImjVrBlweAXnx4kVat25dreM3adKEf/7zn1dtX7x4MampqcycObPiHNLwebs5MOXRKOK+OcS6LUc4kHWW3w0Jw9fLuHsWREREROqCYQG+U6dODBgwgJkzZ5Kbm0tAQACrV68mJyeH119/veJzL7zwAomJiezbt69iW3Z2NvHx8QDs3LkTgDlz5gCXr9zHxsZiY2ND3759rzrvhg0b2LNnT5XvScNmbWXmwbuDaRfoxgdr9vDKoiRG923DXZ18MJlMRpcnIiIiUisMC/AAb775JrNmzSI+Pp5z584REhLC3LlziYqKuu5+WVlZzJ49u9K2K6+HDh2qee+NXMdWHsyY0IUP1uxh0bp97PnpDI8NCMXB3tD/u4uIiIjUClN5uR5pWR2aQtNwlJWX8/mPh1n9TQbuznZMGhJGa1+XWju+emKZ1BfLo55YJvXF8qgnlklTaETqkdlk4r7uLZn8aCTl5fC/S7ex9sfDlOl3VhEREWnAFODlthfs68KMCTFEtPFk1dfpvLN8O+fya/6gMBEREREjKMBLo+Bgb8MTD3Rg7IAQ9medY9r8RHZlnDK6LBEREZFqU4CXRsNkMtG7sy8vPRZNUwdb/r58Bys3HqT0UpnRpYmIiIjcNAV4aXT8vJx48bFoenX24fMtR3j939s4cfai0WWJiIiI3BQFeGmU7GyseGxAKE880IFjpy8wY0EiiWnHjS5LRERE5IYU4KVRiwn1Zsb4GHw8HHkvfjcLP0+jqOSS0WWJiIiIXJMCvDR6nq5NeOGRSO7rHsi3O47y8sKtZJ3IN7osERERkSopwIsA1lZmhvdqzbOjOlNQWMori5PYuC0LPedMRERELI0CvMgvhLV0Z8aELoT4u7Lky/3MWb2LgsISo8sSERERqaAAL/IrLo62PP1gJx68O5jtB08yfX4iB7LOGl2WiIiICKAAL1Ils8nEgK4BTHk0CrPZxBtLU1jzw0+UlWlJjYiIiBhLAV7kOlr5ODNtXBeiQ72I++YQby/fzpnzRUaXJSIiIo2YArzIDTjYWzNpSBjj7g0lPfsc0+Ynkpp+0uiyREREpJGyNroAkYbAZDJxVycfgn1deC9+N7NWpvLTiQIGdvHH2kq/B4uIiEj9UfIQqQYfT0deHBvF3ZG+fLIpndeWJHP8zAWjyxIREZFGRAFepJpsbawY0z+Ev4yL4cSZi0xfsJUfdx8zuiwRERFpJLSERuQWde/og1sTG/7fp7uZ++kedv90mkf6tcXeVt9WIiIiUnd0BV6kBjxc7Hnh4QgG9WjJDzuP8fLCJI4cP290WSIiInIbU4AXqSErs5lhd7Xi+dERXCwu5W+Lk0hIzqK8XDPjRUREpPYpwIvUknaBbsyY0IX2Ld1Zun4//xe3k/yLJUaXJSIiIrcZBXiRWuTsYMtTI8IZFRtMavopps1PZN+RM0aXJSIiIrcRBXiRWmYymejfJYCpY6OwsTbz5ocpxH+XQVmZltSIiIhIzSnAi9SRls2dmTYuhm7tmxH/XQZvfZjC6bxCo8sSERGRBk4BXqQONbGzZuLgMB6/rx0/HTvP9AVb2X7gpNFliYiISAOmAC9SD+7o2IK/jovGvakd736cyrIN+ykpLTO6LBEREWmAFOBF6kkLD0emjo2mb5QfG5KyeHVJEsdOXzC6LBEREWlgFOBF6pGNtZmH+7XlD8M7cupcITMWbOX7nUeNLktEREQaEAV4EQNEtPFixoQuBDZvyrzP0nj/091cLCo1uiwRERFpABTgRQzi7mzPn0dHcH/PIH7cc5wZC7fy07E8o8sSERERC6cAL2Igs9nE/T2D+PPoCEpKy3h1cTJfbs2kvFwz40VERKRqCvAiFiAkwI0ZE7rQsZUHHyUcYPaqVPIuFBtdloiIiFggayNPXlxczOzZs4mPjycvL4/Q0FCeeeYZunfvft39UlNTiYuLIzU1lf3791NSUsK+ffuu+lx6ejoff/wx33//PUeOHMHR0ZGwsDD++Mc/EhYWVldflsgtcWpiwx+GdyQhOYsVGw8yfX4ivx0cRmigm9GliYiIiAUx9Ar85MmTWbRoEUOGDGHq1KmYzWYmTpxISkrKdffbtGkTK1euBMDf3/+an1u1ahUrV66kQ4cOTJ48mXHjxnHo0CEefPBBfvzxx1r9WkRqg8lkom+0Py+OjcbO1pq3Pkxh9TeHuFSmmfEiIiJymancoMW2qampjBw5kilTpjBu3DgAioqKGDRoEN7e3ixduvSa+548eRInJyfs7e159dVXWbx4cZVX4Hft2kVQUBCOjo4V286cOcPAgQMJDg5myZIl1a771Kl8ysrq/5/My6spubnn6/28cm113ZPC4lKWrt/P9zuP0cbPhd8ODsPDxb7Ozne70PeK5VFPLJP6YnnUE8tkRF/MZhMeHk7Xfr8ea6lk3bp12NjYMHLkyIptdnZ2jBgxguTkZE6cOHHNfT09PbG3v3GQ6dChQ6XwDuDm5kZ0dDTp6em3XrxIPbC3tebx+9ozcXB7jpzIZ/qCRLbtzzW6LBERETGYYQE+LS3tqqvjAOHh4ZSXl5OWllZn587NzcXNTeuKpWHoHtac6eNi8HRtwv/F7WTJl/soKb1kdFkiIiJiEMMCfG5uLt7e3ldt9/LyArjuFfiaSEpKYvv27dx77711cnyRutDM3YGpY6LoH+PPxm3ZvLIomZyTBUaXJSIiIgYwbApNYWEhNjY2V223s7MDLq+Hr22nTp3iueeeIyAggAkTJtzSMa63HqmueXk1NezcUrX67skfRkXSvZMv73y4jVcWJzHpgY707RKAyWSq1zosnb5XLI96YpnUF8ujnlgmS+uLYQHe3t6ekpKSq7ZfCe5XgnxtuXDhApMmTeLixYvMmzcPBweHWzqObmKVK4zqSaCnA9PGxfD+p7t5d8V2tuw6yth7QmhiZ+hUWIuh7xXLo55YJvXF8qgnlkk3sf6Cl5dXlctkcnMv36RX1fKaW1VcXMwf/vAH9u/fz5w5cwgODq61Y4sYwa2pHc+PimDoXa3YmnaC6QsSyTiaZ3RZIiIiUg8MC/ChoaFkZGRQUFB5He+OHTsq3q8NZWVlvPDCC2zevJm///3vREdH18pxRYxmNpsY3KMlLzwSQVlZOa8tSWbdliOUGTMZVkREROqJYQF+wIABlJSUVDyQCS5fKY+LiyMyMpJmzZoBkJOTU6ORj3lqkbsAACAASURBVK+88gpr165l2rRp9O3bt8Z1i1iaNn6uTJ/QhU7BnqzYeJBZK3eQV1BsdFkiIiJSRwxbNNupUycGDBjAzJkzyc3NJSAggNWrV5OTk8Prr79e8bkXXniBxMTESg9qys7OJj4+HoCdO3cCMGfOHODylfvY2FgAFi5cyLJly4iIiMDe3r5inyvuv//+Ov0aReqLo70NTw7twNcp2XyYcJBp8xP5zeD2hLV0N7o0ERERqWWG3vX25ptvMmvWLOLj4zl37hwhISHMnTuXqKio6+6XlZXF7NmzK2278nro0KEVAX7v3r0ApKSkkJKSctVxFODldmIymbg70o9gP1fei9/F3z/azsDugdzfMwhrK8P+2CYiIiK1zFRergWz1aEpNHKFJfekqPgSyzbs59vUo7T2cWbSkDA8XZsYXVa9sOS+NFbqiWVSXyyPemKZNIVGROqFna0V4we2Y9KQMLJPFjBtwVaS9tbNw9FERESkfinAi9zGurZvxvQJXWju7sCcT3axeN1eiksuGV2WiIiI1IACvMhtztu1CVMejeTergF8vT2HVxYlkZ2bb3RZIiIicosU4EUaAWsrMyPvDubZBztx/kIxryxK4uvt2egWGBERkYZHAV6kEenQyoMZE7oQ7OfC4nX7+Ff8bi4UlhhdloiIiFSDArxII+PiZMezD3VmRO/WbNuXy/QFW0nPPmd0WSIiInKTFOBFGiGzycTAboFMeTQSgNf/vY3PNv9EmZbUiIiIWDwFeJFGrLWvC9PHxxAZ4sXHmw7x9+XbOZdfZHRZIiIich0K8CKNnIO9DU/cH8bYASEcyDrHtPmJ7Dp0yuiyRERE5BoU4EUEk8lE786+/PWxaJo62PL3FTtYsfEgpZfKjC5NREREfkUBXkQq+Ho58eJj0fTu7MO6LUd4/d/bOHH2otFliYiIyC8owItIJXY2VowdEMrvH+jAsdMXmLEgkcS040aXJSIiIj9TgBeRKkWHejNjfAw+no68F7+bBWvTKCq+ZHRZIiIijZ4CvIhck6drE154OJL7ugfyXepRXl60lcwT+UaXJSIi0qgpwIvIdVlbmRneqzXPjurMhcJSXlmUxFfbsijXzHgRERFDKMCLyE0Ja+nOjAldCA105d9f7uefq3eRf7HE6LJEREQaHQV4Eblpzo62PD2yEw/eHcyOgyeZviCRA1lnjS5LRESkUVGAF5FqMZtMDOgawJRHo7Aym3hjaQqffp9BWZmW1IiIiNQHBXgRuSWtfJyZPr4L0aFerP42g5kfpXDmfJHRZYmIiNz2FOBF5JY1sbNm0pAwxt8byqGjeUybn8iOgyeNLktEROS2pgAvIjViMpm4s5MPf30sBlcnO2avSuWjhAOUXiozujQREZHbkgK8iNQKH09HXnosithIX77cmsmrS5I5fuaC0WWJiIjcdhTgRaTW2Fhb8Wj/EJ4c2pGTZy8yfcFWNu86ZnRZIiIitxUFeBGpdVEhXkwf34UAbyfeX7OHeWv2UFhcanRZIiIitwUFeBGpEx4u9vz54QgG92jJD7uOMWNhEkeOnze6LBERkQZPAV5E6oyV2czQu1rx/OgIiopL+dviJDYkZVJerpnxIiIit0oBXkTqXLtAN6ZP6EL7lu4s23CAf3y8k/yLJUaXJSIi0iDVSoAvLS3liy++YMWKFeTm5tbGIUXkNuPsYMtTI8IZ1acNOw+dYtr8RPYdOWN0WSIiIg2OdXV3ePPNN9myZQsff/wxAOXl5YwfP56kpCTKy8txdXVlxYoVBAQE1HqxItKwmUwm+sf409bfhffid/PmhykMuSOIwT1aYjabjC5PRESkQaj2Ffhvv/2W6OjoitdfffUVW7du5fHHH+ftt98GYO7cubVXoYjcdlo2d2bauBi6tW9O/HcZvPlhCqfzCo0uS0REpEGo9hX4Y8eOERgYWPF648aN+Pn58fzzzwNw4MABPv3009qrUERuS03srJk4uD3tW7rx7y/3M21+IhPua0dEGy+jSxMREbFo1b4CX1JSgrX1f3P/li1b6NGjR8Vrf39/rYMXkZt2R8cWTBsfg4eLPf/4eCdL1++npPSS0WWJiIhYrGoH+ObNm5OSkgJcvtqemZlJTExMxfunTp3CwcGh9ioUkdtec3cHpo6Jpm+0HwnJWby6OJmjpwqMLktERMQiVXsJzX333cecOXM4ffo0Bw4cwMnJiV69elW8n5aWdtM3sBYXFzN79mzi4+PJy8sjNDSUZ555hu7du193v9TUVOLi4khNTWX//v2UlJSwb9++Kj9bVlbGvHnz+PDDD8nNzaVly5Y88cQTDBw48Oa/aBGpczbWZh7u25b2ge7MX5vGywuTeLR/W3p0aI7JpBtcRURErqj2FfhJkyYxdOhQtm/fjslk4o033sDZ2RmA8+fP89VXX90wgF8xefJkFi1axJAhQ5g6dSpms5mJEydWXOG/lk2bNrFy5Urg8pKd63nnnXeYOXMmPXv25KWXXsLHx4dnnnmGdevW3VSNIlK/OrfxZPr4GAKbN2XeZ2l8sGYPF4tKjS5LRETEYpjKa/GRiGVlZRQUFGBvb4+Njc11P5uamsrIkSOZMmUK48aNA6CoqIhBgwbh7e3N0qVLr7nvyZMncXJywt7enldffZXFixdXeQX++PHj9OnTh9GjRzN16lTg8tjLRx99lKNHj7JhwwbM5ur9DnPqVD5lZfX/FEkvr6bk5uox9JZEPalbZWXlrPnhJ+K/z8DLtQm/uz+Mls2db7if+mJ51BPLpL5YHvXEMhnRF7PZhIeH07Xfr82TlZaW0rRp0xuGd4B169ZhY2PDyJEjK7bZ2dkxYsQIkpOTOXHixDX39fT0xN7e/obn2LBhAyUlJTz88MMV20wmE6NHjyY7O5vU1NQbHkNEjGE2mxjSM4g/j46gpLSMVxcn80XiEcpq75qDiIhIg1TtAL9p0yb+8Y9/VNq2dOlSIiMj6dy5M8899xwlJTd+RHpaWhpBQUE4OjpW2h4eHk55eTlpaWnVLa3Kczg5OREUFHTVOQD27NlT43OISN0KCXBjxoQuhLf2YPlXB3l3VSp5F4qNLktERMQw1Q7w8+bN49ChQxWv09PTee211/D29qZHjx6sXbv2ustfrsjNzcXb2/uq7V5el2dAX+8K/M3Kzc3F09OzTs8hInXPqYkN/zOsI4/0a8uen04zbX4iaYfPGF2WiIiIIao9hebQoUOVps6sXbsWOzs7Vq1ahZOTE8899xyffPJJxbr2ayksLKxyqY2dnR1weT18TRUWFmJra1ur57jeeqS65uXV1LBzS9XUk/o1aoAzXTr68OaSJGZ+lMKDfdoyun8IVlaVr0WoL5ZHPbFM6ovlUU8sk6X1pdoB/ty5c7i5uVW8/uGHH+jWrRtOTpeDbZcuXdi0adMNj2Nvb1/lUpsrofpKyK4Je3t7iouv/lN7Tc6hm1jlCvXEGE1tzUwdE8nS9ftZvmE/yXuPM2lwGB4ul++LUV8sj3pimdQXy6OeWCZLvIm12gHezc2NnJwcAPLz89m5cyfPPvtsxfulpaVcunTjpyh6eXlVuYTlylNcq1peU11eXl4kJSXV6TlEpP7Z21rz+H3tad/SncVf7GPa/ETu6NicbftzOZ1XhLuzHcN6taZ7WHOjSxUREal11V4D37lzZz766CPWrVvHa6+9xqVLl7jrrrsq3j98+PBNBePQ0FAyMjIoKKj8tMUdO3ZUvF9T7dq1Iz8/n4yMjCrP0a5duxqfQ0SM0z2sOdPHx9DEzor1SVmcyiuiHDiVV8Siz/eyefcxo0sUERGpddUO8H/84x8pKyvj6aefJi4ujgceeIDg4GDg8oz1DRs2EBkZecPjDBgwgJKSkooHMsHlJ7PGxcURGRlJs2bNAMjJySE9Pb26ZQLQp08fbGxsWLZsWcW28vJyPvroI3x8fOjUqdMtHVdELEczNweqWtRWXFpG3KZb+9khIiJiyaq9hCY4OJi1a9eybds2mjZtSkxMTMV7eXl5PPbYY3Tt2vWGx+nUqRMDBgxg5syZ5ObmEhAQwOrVq8nJyeH111+v+NwLL7xAYmJipQc1ZWdnEx8fD8DOnTsBmDNnDnD5yn1sbCwAzZs3Z+zYscyfP5+ioiI6duzIhg0bSEpK4p133qn2Q5xExDKdzqv6hvRTeUX8dCzvph4AJSIi0lBUO8ADuLq6VoTkX3JxceGxxx676eO8+eabzJo1i/j4eM6dO0dISAhz584lKirquvtlZWUxe/bsStuuvB46dGil2p5//nlcXFxYvnw5cXFxBAUF8fbbbzNw4MCbrlNELJuHsx2nrhHiX16YRBs/F/pF+xPR1hMr/eIuIiINnKm8/NYea3jkyBESEhLIzMwEwN/fnz59+hAQEFCrBVoaTaGRK9QTy7F59zEWfb6X4tKyim221mZG921DUfElNiRncfJcIR7OdvSJ8ueuTi1wsL/xE6Olduh7xTKpL5ZHPbFMt8UUGoBZs2bx/vvvXzVt5q233mLSpEk89dRTt3JYEZFbcmXaTNym9Cqn0PSN9mf7wZOs35rJio0Hif8ugzs6NqdvtD/N3R2MLF1ERKTaqh3gV61axXvvvUdERAS/+c1vaNOmDQAHDhxg3rx5vPfee/j7+zNs2LBaL1ZE5Fq6hzWne1jzKq+UmM0mItt6EdnWi8PHzrMhKZNvduTw1bZswlt70C/Gn/aBbphMJoOqFxERuXnVXkIzbNgwbGxsWLp0KdbWlfN/aWkpjzzyCCUlJcTFxdVqoZZCS2jkCvXEMt1sX87lF7ExJZuvU7LJu1CCr6cjfaP96B7WHFsbq3qotPHQ94plUl8sj3pimSxxCU217+ZKT09n4MCBV4V3AGtrawYOHHjLYx9FROqLi5MdD9zZird+fweP39cOK7OJRev28fycH/h4Uzpnzld9U6yIiIjRqr2ExsbGhgsXLlzz/YKCAmxsdHOYiDQMNtZm7ujYgh4dmrM/8yxfbs1k7ebDrNtyhJhQb/pG+9PKR2MoRUTEclQ7wHfs2JHly5czcuRIPD09K7136tQpVqxYoQckiUiDYzKZCAlwIyTAjRNnL5KQlMW3qTn8uOc4wb4u9IvxJ1JjKEVExAJUO8D//ve/Z9y4cQwcOJDhw4dXPIX14MGDxMXFUVBQwMyZM2u9UBGR+uLt2oTRfdvwwJ1BfJd6lA3Jmfzrk124O9vRJ9KPuzr74KgxlCIiYpBbmgP/1Vdf8corr3D06NFK2318fPjrX/9K7969a6s+i6ObWOUK9cQy1UVfysrK2ZF+eQzl3iNnsbUxc0eHFvSN9qOFh2Otnut2pO8Vy6S+WB71xDJZ4k2stzQHPjY2lt69e7Nr1y6ysrKAyw9yCgsLY8WKFQwcOJC1a9feWsUiIhbGbDYR0caLiDZeHDl+ng0/L6/ZmJJNx1Ye9IvxI6ylu8ZQiohIvbilAA9gNpsJDw8nPDy80vYzZ86QkZFR48JERCxRQLOmTLivHSN6t+brlGy+Ssnm78t30MLDgX7R/nTv0Bw7jaEUEZE6dMsBXkSkMXN2tGVIzyDu7RZIYtpx1idlsviLfXy8KZ1enX2JjfTF3dne6DJFROQ2pAAvIlIDvxxDeSDrHOu3ZvL5lstjKKNDvegX409rHxejyxQRkduIAryISC0wmUy09Xelrb8ruWcvkpB8eZ18YtoJWvs40zfan6gQL6ytNIZSRERqRgFeRKSWebk2YVSfNtzfM4gfdh1jfVIm/+8/u3FrakdspC+9Ovvi1ERjKEVE5NbcVIBfsGDBTR9w27Ztt1yMiMjtpImdNX2i/Lg70pfU9FOs35rJx5sO8en3P9GjQ3P6RPvj66kxlCIiUj03FeDfeOONah1Uo9RERP7LbDLROdiTzsGeZJ3IZ31SJt/tPMbX23PoEORO32h/OrRyx6yfnSIichNuKsAvXry4rusQEWkU/LydGD+wHcN7t2bTz2MoZ63cQXN3B/pF+9GjQwvsbDWGUkREru2mAnyXLl3qug4RkUbF2cGWwXdcHkO5de8JvtyayZIv9/PxpkP06uxDbKQfHi4aQykiIlfTTawiIgaytjLTPaw53do342D25TGU6xKP8EViJlEhV8ZQOmtpooiIVFCAFxGxACaTiTZ+rrTxc+XkuYt8lZzNph05bN17gqAWTekX7U90qLfGUIqIiAK8iIil8XRpwoOxwQzp2fLnMZRZzP10Dys2HiQ20o9enX1o6mBrdJkiImIQBXgREQtlb2tNbKQfvSN82XXo8hjKuG8O8ekPP9E9rDn9ov3w9XIyukwREalnCvAiIhbObDIR3tqT8NaeZOXmsyEpi827j/HNjhzCWrrRL8afDq08NIZSRKSRUIAXEWlA/LycGHdvKMN7teKbHTkkJGcxa2Uqzdwd6Bvlxx0dm2Nvqx/tIiK3M/2UFxFpgJo62HJf95bc0yWApH0nWL81k6Xr9xP3zSF6dfIhNsoXT5cmRpcpIiJ1QAFeRKQBs7Yy0619c7q2a0Z6Th7rt2by5dZMvth6hKi2XvSN9qeNn4vGUIqI3EYU4EVEbgMmk4lgXxeCfV04nVdIwrYsvtmeQ9K+XAKbN6V/tD8x7TSGUkTkdqAALyJym3F3tmdk72CG9Ajih93HWL81k/fXXBlD6UuvCF+cNYZSRKTBUoAXEblN2dlacXeEL706+7A74zTrt2ay+tsMPv3hMN3DmtEv2h8/b42hFBFpaBTgRURuc2aTiY6tPOjYyoPskwUkJGXyw65jfJt6lHaBbvSL9ic8WGMoRUQaCgV4EZFGxNfTkbEDQhnWq3XFGMp3P07F263Jz2MoW9DETv9pEBGxZPopLSLSCDk1sWFgt0D6x/izbX8u67dmsmzDAVZ/e4g7w33oE+WHl6vGUIqIWCJDA3xxcTGzZ88mPj6evLw8QkNDeeaZZ+jevfsN9z1+/DivvfYa33//PWVlZXTr1o0pU6bg7+9f6XPnz59nzpw5JCQkcOzYMTw9PenZsydPPvkkzZo1q6svTUSkQbC2MtOlXTO6tGtGevY51idlsiEpi/VJmUS08aJftB9t/V01hlJExIKYysvLy406+bPPPsuXX37J2LFjCQwMZPXq1ezatYslS5YQERFxzf0KCgoYNmwYBQUFjBs3DmtraxYuXIjJZOKTTz7BxcUFgLKyMkaNGsWBAwcYPXo0QUFBZGRk8OGHH+Ll5cWaNWuwta3eJIZTp/IpK6v/fzIvr6bk5p6v9/PKtaknlkl9qbnTeYV8tS2bTduzKSgsJaCZE/2i/enSrhk21tUfQ6meWCb1xfKoJ5bJiL6YzSY8PK49ZMCwK/Cpqal89tlnTJkyhXHjxgHwwAMPMGjQIGbOnMnSpUuvue+yZcs4fPgwcXFxtG/fHoA777yTwYMHs3DhQp566ikAdu7cyY4dO/jrX//KI488UrG/j48Pr7zyCtu2baNbt25190WKiDRA7s72jOjdmsF3tGTzz2Mo532Wxsqv04mN8KV3hC/OjhpDKSJiFMOe6LFu3TpsbGwYOXJkxTY7OztGjBhBcnIyJ06cuOa+X3zxBZ07d64I7wCtW7eme/fufP755xXb8vPzAfDw8Ki0v6enJwD29va18rWIiNyO7Gys6N3Zl7/9pivPPtSJwGZN+eS7DJ6f8z3zP0vjyHFdKRQRMYJhV+DT0tIICgrC0dGx0vbw8HDKy8tJS0vD29v7qv3KysrYt28fDz300FXvdezYke+//56LFy/SpEkTwsLCcHBwYPbs2bi4uNCqVSsOHTrE7Nmz6dq1K506daqzr09E5HZhMpnoEORBhyAPjp4qYENyFt/vPMp3O48SGuBKv2h/OgV7YjZrnbyISH0wLMDn5uZWeROpl5cXwDWvwJ89e5bi4uKKz/163/LycnJzcwkICMDV1ZV33nmHF198sWKZDsDdd9/NrFmzdFOWiEg1tfBwZEz/EIbd1apiDOU/4nbi5WpP3yh/eoZrDKWISF0z7KdsYWEhNjY2V223s7MDoKioqMr9rmyv6ubTK/sWFhZWbHN3d6dDhw5ERETQunVr9u7dywcffMBf/vIX/v73v1e77uvdUFDXvLyaGnZuqZp6YpnUl7rnBbT0d+eRe9uzeddR/vPNIT5MOMAn32XQr2sAg3u2ornHf//Cqp5YJvXF8qgnlsnS+mJYgLe3t6ekpOSq7VcC+pUw/mtXthcXF19z3ytr2zMzMxk7diwzZ86kb9++APTt2xdfX18mT57M8OHDueOOO6pVt6bQyBXqiWVSX+pfiI8zfxrVmUM5eWxIyuSz7zL49JtDdG7jSb9of3pG+XPyZL7RZcqv6HvF8qgnlklTaH7By8urymUyubm5AFWufwdwdXXF1ta24nO/3tdkMlUsr4mLi6O4uJhevXpV+lxsbCwA27Ztq3aAFxGRqrXycea3Q8IYeXcwG1Oy+Dolh5QDJ1m5KZ27O/vStb03NtZWRpcpItLgGTaFJjQ0lIyMDAoKCipt37FjR8X7VTGbzbRt25Zdu3Zd9V5qaiqBgYE0aXL56YGnTp2ivLycX4+6Ly0trfS/IiJSe9ya2jHsrtbM/H0Pxt0byqWycuavTeNPc37gk28PcS6/6iWSIiJycwwL8AMGDKCkpISVK1dWbCsuLiYuLo7IyMiKG1xzcnJIT0+vtO8999zD9u3b2bNnT8W2Q4cO8eOPPzJgwICKbS1btqSsrKzSaEmANWvWAFQaQykiIrXL1saKuzr58H/P381zozrTsoUz//n+J/70rx+Yt2YPh49pqYCIyK0w9EmsTz31FAkJCTz22GMEBARUPIl10aJFREVFATBmzBgSExPZt29fxX75+fkMHTqUixcvMn78eKysrFi4cCHl5eV88sknuLm5AXDmzBkGDx7M2bNnGT16NMHBwezevZtVq1YRHBzMxx9/XOWNtNejNfByhXpimdQXy/PLnhw7fYGEpCy+23mUopJLtPW/PIYyoo3GUNY3fa9YHvXEMlniGnhDA3xRURGzZs3i008/5dy5c4SEhPDss8/So0ePis9UFeABjh07xmuvvcb3339PWVkZXbt2ZerUqfj7+1f63PHjx5k9ezZbtmzh+PHjuLq6EhsbyzPPPFMR9KtDAV6uUE8sk/piearqyYXCEr7ZcZSE5CxO5RXi6WJP3yg/eob74GCvMZT1Qd8rlkc9sUwK8LcBBXi5Qj2xTOqL5bleTy6VlZGy/yTrkzI5kHUOO1sr7uzYgj7RfjRzc6jnShsXfa9YHvXEMlligNdlDhERMYyV2Ux0qDfRod5kHL08hnJjSjYJyVl0CvakX7QfoYFuevCeiMgvKMCLiIhFCGrhzMTBP4+h3JbNxpRsth88iZ+XI/2i/ekW1kxjKEVEUIAXEREL4+pkx9C7WjGoRyA/7j7O+qRMFny+l1Wb0und2Ze7I31xdar6YX8iIo2BAryIiFgkG2sr7uzkQ8/wFuw9fIb1SVms+eEn1v54mC7tvOkX40/L5s5GlykiUu8U4EVExKKZTCbatXSnXUt3jp+5PIby251H2bz7OG38XC6PoWzriZXZsEebiIjUKwV4ERFpMJq5OfBwv7Y8cGcrvkvNYUNyFnM+2YWHsz19ovy4q1MLHOyr93wPEZGGRgFeREQaHAd7a/p3CaBvtD8pBy6PoVyx8SDx32XQs2ML+kb70cxdYyhF5PakAC8iIg2W2WwiKsSLqBAvDh87z4akTDbtyCZhWxbhrT3oF+NPe42hFJHbjAK8iIjcFgKbN+XxQe0Z0bs1G1Oy+Tolm7c/2o6vpyP9Yvzp1r4ZtjYaQykiDZ8CvIiI3FZcnOx44M5W3Nc9kC17TrA+KZOFn+9l1dfp9OrsQ2ykH25NNYZSRBouBXgREbkt2Vhb0TO8BXd0bM6+I2dZn5TJ2s2HWbflCDGhl8dQBrXQGEoRaXgU4EVE5LZmMpkIDXQjNNCNE2cukJCczbepOfy45zjBvi70i/EnUmMoRaQBUYAXEZFGw9vNgdF92/DAnUF8l3qUDcmZ/OuTXbg72/08htIHR42hFBELpwAvIiKNThM7a/rF+NMnyo8dBy+PoVy5MZ347zK4o8PlMZQtPByNLlNEpEoK8CIi0miZzSYi2noR0daLI8fPsyEpi29Tc9iYkk3HVh70i/EjrKW7xlCKiEVRgBcREQECmjVlwn3tGN67NZtSsvkqJZu/L9+Bj6cjfaP96B7WHDuNoRQRC6AALyIi8gsujrYM6RnEvd0CSUw7zvqkTBav28fHX6fTO8KXuyN8cXe2N7pMEWnEFOBFRESqYGNt5o6OLejRoTn7M8+yISmLtT9eHkMZFeJFvxh/Wvu4GF2miDRCCvAiIiLXYTKZCAlwIyTAjdyzF0lIvrxOPjHtBK19nH8eQ+mFtZXGUIpI/VCAFxERuUlerk0Y1acN9/cM4vudR9mQlMV78btxa/rfMZROTTSGUkTqlgK8iIhINTWxs6ZvtD+xUX6kpp9i/dZMVn2dzn++y6BHh+b0jfbHx1NjKEWkbijAi4iI3CKzyUTnYE86B3uSdSKf9UmZfLfzGF9vz6FDkDv9YvwJC3LHrDGUIlKLFOBFRERqgZ+3E+MH/mIM5bZs3lmxgxYeDvSN9qdHWHPsbDWGUkRqTgFeRESkFjk72DL4jstjKLemneDLpEyWfLGPuE3p3NXZhz6RfhpDKSI1ogAvIiJSB6ytzHTv0JxuYc04mH2O9VszWbflCF9syfzFGEpnPeVVRKpNAV5ERKQOmUwm2vi50sbPlZPnLvJVcjabduSwde8Jglo40y/Gj+gQb42hFJGbpgAvIiJSTzxdmvBgbDD/v717j4vqvPMH/pk7yH2GAZQ7g4DcL6YI8X6J1JJ6i7FJlFxamzRmX2q6fSXWdndrW93dGGtiN20SkyX6S5MNFiTqetfGBDQmGkEEUQZECHIbROQ6yJzfHwNnRcAY6PTrnAAAIABJREFUucwMfN7/GJ7zPM5z+Hpyvjw853t+PDUAOReqcfRsJd75tBCfOJZgdrwPZsROgNM4paWnSURWjgk8ERHRCLNTyjEnwQez4r1RUGouQ5l5shR7c68iKcIL8yb7wFvraOlpEpGVYgJPRERkIVKJBNE6d0Tr3FFZ14yjX1fi1MVqnMyrQkSAG+Y95IvIIA3LUBJRL0zgiYiIrICP1hHP/DAMS2cE4bPzVTh+rhLbMvLhqR6HeZN9kBzpBTslb9tExASeiIjIqjiNUyI1OQApiX74+lItjnxdgf93+DIyPyvF9JgJmJ3gDXcXe0tPk4gsiAk8ERGRFZLLpJgS4YXEcE/oq5pw5KsKHP6qAoe+uoaEEHMZymBvF5ahJBqDmMATERFZMYlEgmBvFwR7u8Bwsx3Hz1Xis/NV+Lq4DgFeTpj3kC8eCmMZSqKxxKJXu9FoxGuvvYapU6ciOjoajz/+OE6dOnVfY2tqarBmzRpMnjwZ8fHxePHFF1FRUdFv39raWmzYsAFTp05FVFQU5s6di82bNw/lqRAREQ07jYsdls0KxuurH8bKR0LQbuzCu3sL8au/5GJv7lU0tRotPUUiGgEWXYF/9dVXcfjwYaSlpcHf3x9ZWVlYtWoVdu3ahbi4uAHHtbS0IC0tDS0tLXjhhRcgl8uRnp6OtLQ07NmzBy4uLmLfb7/9Fk888QQcHR2RlpYGNzc3VFdXo6ysbCROkYiIaMiplDLMivfBjDhvFJQ24OjXFcg6WYq9OVeRFOGJeZN94ePBMpREo5XFEvj8/Hzs378f69evxzPPPAMAWLRoEVJTU7FlyxZ8+OGHA47929/+hvLycmRmZiI8PBwAMG3aNDz66KNIT0/HmjVrxL7/8i//Ai8vL+zcuRN2dnbDek5EREQjyVyGUoNonQbf1rfg2NcVyC2oxuf51zHJ31yGMlrHMpREo43FttAcPHgQCoUCy5YtE9tUKhUee+wxnD17FrW1tQOOPXToEGJjY8XkHQB0Oh2SkpJw4MABsU2v1+OLL77A6tWrYWdnh7a2Nty+fXt4ToiIiMiCvN0dkJYShi2rH8bSGUGobmjFm7vz8et3TuPY2Uq0dZjvf6cuVuNXb+Xgx7/Mxq/eysGpi9UWnjkRfV8WW4EvKipCYGAgHBwcerVHR0dDEAQUFRXBw8OjzziTyYTi4mIsX768z7GoqCjk5OSgra0N9vb2yM3NBQAolUosWbIEFy9ehEKhwOzZs/Fv//ZvUKvVw3NyREREFuJor8CPkgIw/wd+OHe5Dke+qsCHRy4j86QeugkuKK5oROdtEwDA0NSBDw5cAgAkRXhZctpE9D1YLIGvq6uDp6dnn3atVgsAA67ANzY2wmg0iv3uHisIAurq6uDn54fy8nIAwNq1azF16lQ8//zzKCkpwV//+ldUVlYiIyMDMplsCM+KiIjIOshlUvxgkid+MMkT+m9v4sjXFThT1PfearxtQuZneibwRDbEYgl8e3s7FApFn3aVSgUA6Ojo6HdcT7tSqRxwbHt7OwCgtbUVgHll/vXXXwcAzJ8/H66urti4cSNOnDiBuXPnfq95azSWeyhIq3Wy2GdT/xgT68S4WB/GxLK0WidMifXBo7/M7ve4oakDHQLgrXVkXXkL47VinawtLhZL4O3s7NDZ2dmnvSdB70nG79bTbjT2LZXVM7bnYdWeP1NTU3v1+/GPf4yNGzfi3Llz3zuBNxiaYTIJ32vMUNBqnVBXd2vEP5cGxphYJ8bF+jAm1kPjrIKhqf8Fsl/8x3F4uNqbH4oN1iDU1xUKOX9LPZJ4rVgnS8RFKpXcc9HYYgm8Vqvtd5tMXV0dAPS7/x0AXF1doVQqxX53j5VIJOL2mp4/NRpNr35OTk5QKpVoamoa1DkQERHZkiUzdPjgwCUYu/fAA4BSLsXiGUGQS6XI1xvwWV4Vjp6thFIhRbi/GtHBGkQHaaB2ZiU3ImthsQQ+LCwMu3btQktLS68HWfPy8sTj/ZFKpQgJCUFBQUGfY/n5+fD394e9vT0AICIiAoD5pU93amhogNFo5EOsREQ0pvTsc8/8TI+Gpg6onVVYMkMnts9J8EFHZxculd9Avt6AfH09zpfUAwB8tI6ICTaXrNRNcIFUyq02RJZisQQ+JSUF77//PjIyMsQ68EajEZmZmYiPjxcfcK2qqkJbWxt0Op04dv78+di6dSsKCwvFUpKlpaU4ffo0Vq1aJfZLTEyEm5sbMjMzsWTJEkil5qqZGRkZAICkpKSROFUiIiKrkRThhaQIrwG3BagUMsQEuyMm2B2CEIKq+hbk6w3I0xtw4PQ17D9VDgc7OaKCNIjSaRAVpIGjfd9n2oho+EgEQRj5Dd3d1qxZg2PHjuHpp5+Gn58fsrKyUFBQgA8++AAJCQkAgJUrV+LMmTMoLi4WxzU3N2Px4sVoa2vDs88+C5lMhvT0dAiCgD179sDNzU3su3v3bmzYsAHJycmYO3cu9Ho9PvroI0yfPh1vv/32954z98BTD8bEOjEu1ocxsU4PEpeW9k5cLGtAvt6AC6UG3GrthEQC6Ca4IEqnQYxOA18PPgj7oHitWCdr3ANv0QS+o6MD27Ztw969e3Hz5k2Ehobi5ZdfRnJystinvwQeAKqrq7Fp0ybk5OTAZDIhMTERGzZsgK+vb5/Pyc7Oxo4dO1BWVgZXV1ekpqZi7dq1D/RmVibw1IMxsU6Mi/VhTKzTYONiEgSUXW/Che7V+fJq89/l5qRCVJB5q014gBvslBb7Zb/N4bVinZjAjwJM4KkHY2KdGBfrw5hYp6GOS2NzBy7oDcgvNeBiWQPajV2QyyQI9XVFtM4d0ToNPNXjhuzzRiNeK9bJGhN4/lhMREREg+bqqMK0mAmYFjMBt7tMuFLRiLzurTYfHbuCj45dgaebvZjMh/i6QiGXWnraRDaJCTwRERENKblMikkBakwKUOMncyaitrEN+SX1yC814MQ33+LI1xVQKWUI93dDTLA7ooI0cHPq//0vRNQXE3giIiIaVh6u9pg72RdzJ/uiw9iFovIbyNfXI09vwDdXzGUq/TwczTXnde4IGu/MMpVE98AEnoiIiEaMSilD7ER3xE50hyAI+LauBXn6euTrDdh/qhz7csvhaK9AZJAa0ToNIgNZppLobkzgiYiIyCIkEgl8PBzh4+GIHyUFoKW9EwWlDcjX1+NCaQNOX6wxl6n0dkGMzrw676N1YJlKGvOYwBMREZFVcLBTIDHcE4nhnjCZzGUq87rfCPv3z0rx989K4eakQrSuu0ylvxoqpczS0yYacUzgiYiIyOpIpRLovF2g83bBkulBuHGrAxdKDcjXG3C6sAafna+CXCZFmJ+r+BIpDzeWqaSxgQk8ERERWT03JxWmx0zA9JgJ6LxtwuXKRvElUh8dvYKPjl6Bl3qcuDof4usKuYxlKml0YgJPRERENkUhlyIiQI2I7jKVNTdaka83r84fP1eJw19VwE4pQ0SAGlHdCb2rI8tU0ujBBJ6IiIhsmqfbOMybPA7zJvui3XgbRVdvIL97u83Zy3UAAH9PJ/PqfLAGgV4sU0m2jQk8ERERjRp2SjniQrSIC9FCEARU1DabV+dLDdh36ir25l6Fo70CUUEaxARrEBGohoMdy1SSbWECT0RERKOSRCKBn6cT/DydkJocgOa2ThSUGrpX5+tx6mI1pBIJgr2dER3sjmidBt7uLFNJ1o8JPBEREY0JjvYKTInwwpQIL5hMAkqrmsSXSO3+hx67/6GHxlmFKJ05mZ/k7waVgmUqyfowgSciIqIxRyqVINjHBcE+Llg6Q4cbtzqQ353Mnyqoxj+++dZcptLfFTHdCb3W1d7S0yYCwASeiIiICG5OKsyI9caMWG9zmcqKRnF1/sMjl/HhEWC8pqdMpTsm+riwTCVZDBN4IiIiojso5FJEBKoREajGk3OB6oaeMpX1OPp1JQ6dqYC9SobwALU5oQ/SwIVlKmkEMYEnIiIiugcv9Th4qcfhkYd80dZxG0XlN8TtNmeLzWUqA7ycxNX5gPFOkPJBWBpGTOCJiIiI7pO9So74EC3iu8tUXqtpFqva7M25ik9zrsJ5nLlMZZROg8hANcaxTCUNMSbwRERERA9AIpHA38sJ/l5OeDQ5ALdajSgobUB+qQHnS+qRU2AuUznRxwXRweatNhNYppKGABN4IiIioiHgNE6JpEgvJEV6octkgv7bJlwoNSCvxICME3pknNBD42yH6GANYnQahPm5QckylfQAmMATERERDTGZVIoQX1eE+Lpi6QwdGpraux+ENSDnwnWcOPctFHIpJvm7iQ/CarVOlp422Qgm8ERERETDTO1sh5lx3pgZ543O210ovtaIvO7KNvl6AwDA19MJEQFuiNFpoPNmmUoaGBN4IiIiohGkkMsQGaRBZJAGT86dKJapLLrWiCNfVeDgl9dgr5IjIlCNGJ0GUUEaODsoLT1tsiJM4ImIiIgsRCKRYLzGAeM1Dljxowhcq7yBwqsNyNMbcEFvwNeXaiEBEDDeubtMpQb+XixTOdYxgSciIiKyEvYqORJCPZAQ6gGTIKCipll8I+ynX5Qh+4syODsoER1kTubDA9QYZ8d0bqxhxImIiIiskPSOMpU/fjgQTa1GFJSaH4Q9d7kOX1y4Dpm0u0ylzh3ROg3Ga8axTOUYwASeiIiIyAY4j1MiOXI8kiPHi2Uqe1bnPzlRgk9OlMDdxQ4xOndE6TQI83NlmcpRigk8ERERkY25s0zlspnBqL/ZhgvdZSo/z6/CsXOVUPaUqQx2R3SQBhoXO0tPm4YIE3giIiIiG+fuYo9Z8T6YFe8DY2cXLl1rFEtU5nWXqfTWOog154N9XCCTskylrWICT0RERDSKKBUysWKNIAi4bmjtfolUPQ6fqcCB09cwTiVHZJAa0TpzOUvncSxTaUuYwBMRERGNUhKJBBPcHTDB3QEpiX5obb/dXaayHhdKG3CmyFymMnCCuUxljM4dfp6OfBDWyjGBJyIiIhojxtnJMTnMA5PDzGUqy6tviavzez4vw57Py+DiqERUkAYx3WUq7VVMF62NRSNiNBrxxhtvIDs7G01NTQgLC8O6deuQlJT0nWNramqwadMm5OTkwGQyYcqUKVi/fj18fX0HHJOXl4fly5dDEAR89dVXcHZ2HsrTISIiIrIZUokEgeOdETjeGQunBuJmi7lMZZ7egLPFtfgi31ymMsTXVdyS46VmmUprIBEEQbDUh7/88ss4fPgw0tLS4O/vj6ysLBQUFGDXrl2Ii4sbcFxLSwuWLFmClpYWPPPMM5DL5UhPT4dEIsGePXvg4uLSZ4wgCHj88cdRUlKC1tbWB07gDYZmmEwj/y3Tap1QV3drxD+XBsaYWCfGxfowJtaJcbE+1hST210m6L+9ibzuyjZV9S0AAA9Xe0TpzKvzoX6uUMhHf5lKS8RFKpVAo3Ec8LjFVuDz8/Oxf/9+rF+/Hs888wwAYNGiRUhNTcWWLVvw4YcfDjj2b3/7G8rLy5GZmYnw8HAAwLRp0/Doo48iPT0da9as6TMmKysL165dw9KlS7Fr165hOSciIiKi0UAukyLUzw2hfm54fFYw6hvbkN/9EqmTeVU4drYSSoUU4f5qcXVe7cwylSPFYgn8wYMHoVAosGzZMrFNpVLhsccew5/+9CfU1tbCw8Oj37GHDh1CbGysmLwDgE6nQ1JSEg4cONAngW9ubsbWrVvx0ksvobGxcXhOiIiIiGiUcne1x+x4H8yO90FHZxeKr90wr86XGHC+pB4A4KN1REywBlFBGui8nVmmchhZLIEvKipCYGAgHBwcerVHR0dDEAQUFRX1m8CbTCYUFxdj+fLlfY5FRUUhJycHbW1tsLe3F9vfeustODo64oknnsBf/vKXoT8ZIiIiojFCpZAhWueOaJ07hHkCqupbuh+ENeDA6WvYf6ocDnZyRAaZV+YjA9VwYpnKIWWxBL6urg6enp592rVaLQCgtra233GNjY0wGo1iv7vHCoKAuro6+Pn5AQCuXr2KnTt3Yvv27ZDL+RQ1ERER0VCRSCTw1jrCW+uIH07xR2t7JwrKGsxvhS014MvCGkgkQNAEZ0Tr3BGj08DXg2UqB8tiGW17ezsUCkWfdpVKBQDo6Ojod1xPu1LZ9ye5nrHt7e1i2+bNm/HQQw9h1qxZg54zgHs+UDDctFoni3029Y8xsU6Mi/VhTKwT42J9RkNM/H3V+NH0YJhMAkoqG/FVYQ2+vlSDrJOlyDpZCrWzHSZP8sTkSZ6ImeiOcXZ980FrY21xsVgCb2dnh87Ozj7tPQl6TzJ+t552o9E44Fg7O/NDFCdPnsTnn3+OrKysIZkzwCo09H8YE+vEuFgfxsQ6MS7WZzTGxM1ejkcSvPFIgjduNnf834Ow31Ti8JflkMt6ylSaV+c91eMsPeU+WIXmDlqttt9tMnV1dQAw4AOsrq6uUCqVYr+7x0okEnF7zWuvvYbZs2fDwcEBlZWVAICmpiYAQFVVFdrb2wf8HCIiIiIaOi6OKkyLnoBp0RNwu8uEK5U3ka+vR77egI+PXcHHx67Aw81efCNsiK8rFHI+CNsfiyXwYWFh2LVrF1paWno9yJqXlyce749UKkVISAgKCgr6HMvPz4e/v7/4AOv169dx+fJlHDlypE/fhQsXIiYmBp988slQnA4RERER3Se5TIpJ/m6Y5O+G5bMnoraxDRf0BuTp6/GPb6pw9OtKqBQyhAe4dZepdIebU/+7M8YiiyXwKSkpeP/995GRkSHWgTcajcjMzER8fLz4gGtVVRXa2tqg0+nEsfPnz8fWrVtRWFgolpIsLS3F6dOnsWrVKrHfli1bcPv27V6fu3//fvzv//4vXnvtNYwfP36Yz5KIiIiIvouHqz3mJPhgToK5TGVR+Y3uyjb1+OZKPYBi+Ho4iqvzQROcIZWO3QdhLZbAx8TEICUlBVu2bBGrxmRlZaGqqgqbN28W+73yyis4c+YMiouLxbYnn3wSGRkZ+PnPf45nn30WMpkM6enp0Gq14g8DADBz5sw+n1tUVCQee5A3sRIRERHR8FEpZIgNdkdssDsEIQTf1rWY986X1ItlKh3tFYgMUiM6SIPIIA0c7a3/QdihZNG6iv/5n/+Jbdu2ITs7Gzdv3kRoaCjeeecdJCQk3HOco6Mjdu3ahU2bNuGtt96CyWRCYmIiNmzYADc3txGaPRERERENJ4lEAh8PR/h4OGLBFH+0tHfiYlkD8koMuFBqwOmL5jKVOm8XxOjML5EaC2UqJYIgjHxJFRvGKjTUgzGxToyL9WFMrBPjYn0Yk+/HZBJQdr1JfIlUeY35e+fmpDLvmw/SYFKAG+yUg1uvZhUaIiIiIqIhIJVKoPN2gc7bBYunB+HGrQ5cKDXggt6A04U1+Ox8FeQyCUL9eh6E1cDTzfrKVD4IJvBEREREZPPcnFSYHjMB02PMZSovVzSKq/MfHb2Cj45egad6HGK6k/kQX1fIZbZZppIJPBERERGNKnKZFOEBaoQHqPGTORNRe6MVeXrz6vzxc5U4/FUFVEoZIgLUiO7eO393mcpTF6uR+ZkeDU0dUDursGSGDkkRXhY6o96YwBMRERHRqObhNg7zJo/DvMm+6DB2obC8QVydP3fZ/HJQP09H8Y2wNTdasfNgMYy3TQAAQ1MHPjhwCQCsIolnAk9EREREY4ZKKUPcRC3iJmohCAIq61qQr69Hnt6A/aeuYl/uVUgkwN1lXoy3Tcj8TM8EnoiIiIjIUiQSCXw9HOHr4YgfJQWgua0TBWUGvPNpYb/9DU0dIzzD/tnmzn0iIiIioiHmaK/AlHAvaJxV/R4fqH2kMYEnIiIiIrrDkhk6KOW902SlXIolM3QWmlFv3EJDRERERHSHnn3urEJDRERERGQjkiK8kBThZZVvyOUWGiIiIiIiG8IEnoiIiIjIhjCBJyIiIiKyIUzgiYiIiIhsCBN4IiIiIiIbwgSeiIiIiMiGMIEnIiIiIrIhTOCJiIiIiGwIE3giIiIiIhvCN7F+T1KpZEx+NvWPMbFOjIv1YUysE+NifRgT6zTScfmuz5MIgiCM0FyIiIiIiGiQuIWGiIiIiMiGMIEnIiIiIrIhTOCJiIiIiGwIE3giIiIiIhvCBJ6IiIiIyIYwgSciIiIisiFM4ImIiIiIbAgTeCIiIiIiG8IEnoiIiIjIhjCBJyIiIiKyIXJLT2AsMxqNeOONN5CdnY2mpiaEhYVh3bp1SEpK+s6xNTU12LRpE3JycmAymTBlyhSsX78evr6+IzDz0etBY7J9+3b8+c9/7tPu7u6OnJyc4ZrumFBbW4udO3ciLy8PBQUFaG1txc6dO5GYmHhf4/V6PTZt2oRz585BoVBg1qxZeOWVV6BWq4d55qPbYOLy6quvIisrq097TEwMPvnkk+GY7piQn5+PrKwsfPnll6iqqoKrqyvi4uKwdu1a+Pv7f+d43leG3mBiwvvK8Llw4QL++te/orCwEAaDAU5OTggLC8Pq1asRHx//neOt4VphAm9Br776Kg4fPoy0tDT4+/sjKysLq1atwq5duxAXFzfguJaWFqSlpaGlpQUvvPAC5HI50tPTkZaWhj179sDFxWUEz2J0edCY9Ni4cSPs7OzEr+/8b3owZWVlePfdd+Hv74/Q0FB888039z22uroaTz31FJydnbFu3Tq0trbi/fffx+XLl/HJJ59AoVAM48xHt8HEBQDs7e3xu9/9rlcbf6ganB07duDcuXNISUlBaGgo6urq8OGHH2LRokXYvXs3dDrdgGN5Xxkeg4lJD95Xhl5FRQW6urqwbNkyaLVa3Lp1C3v37sWKFSvw7rvv4uGHHx5wrNVcKwJZRF5enhASEiL893//t9jW3t4uzJ07V3jyySfvOfadd94RQkNDhYsXL4ptJSUlwqRJk4Rt27YN15RHvcHE5M033xRCQkKEmzdvDvMsx55bt24JDQ0NgiAIwpEjR4SQkBDh9OnT9zX2X//1X4XY2FihurpabMvJyRFCQkKEjIyMYZnvWDGYuLzyyitCQkLCcE5vTDp79qzQ0dHRq62srEyIjIwUXnnllXuO5X1leAwmJryvjKzW1lYhOTlZ+PnPf37PftZyrXAPvIUcPHgQCoUCy5YtE9tUKhUee+wxnD17FrW1tQOOPXToEGJjYxEeHi626XQ6JCUl4cCBA8M679FsMDHpIQgCmpubIQjCcE51THF0dISbm9sDjT18+DBmz54NT09PsS05ORkBAQG8VgZpMHHp0dXVhebm5iGaEcXHx0OpVPZqCwgIwMSJE6HX6+85lveV4TGYmPTgfWVk2NvbQ61Wo6mp6Z79rOVaYQJvIUVFRQgMDISDg0Ov9ujoaAiCgKKion7HmUwmFBcXIzIyss+xqKgoXL16FW1tbcMy59HuQWNyp5kzZyIhIQEJCQlYv349Ghsbh2u69B1qampgMBj6vVaio6PvK540fFpaWsRrJTExEZs3b0ZHR4elpzXqCIKA+vr6e/6wxfvKyLqfmNyJ95Xh09zcjIaGBpSWlmLr1q24fPnyPZ95s6ZrhXvgLaSurq7XqmAPrVYLAAOu9jY2NsJoNIr97h4rCALq6urg5+c3tBMeAx40JgDg7OyMlStXIiYmBgqFAqdPn8b//M//oLCwEBkZGX1WYGj49cRroGvFYDCgq6sLMplspKc25mm1WvzsZz/DpEmTYDKZcOLECaSnp0Ov12PHjh2Wnt6o8umnn6Kmpgbr1q0bsA/vKyPrfmIC8L4yEn7961/j0KFDAACFQoGf/OQneOGFFwbsb03XChN4C2lvb+/3ATqVSgUAA65E9bT3d+H2jG1vbx+qaY4pDxoTAHj66ad7fZ2SkoKJEydi48aN2LNnDx5//PGhnSx9p/u9Vu7+jQsNv1/+8pe9vk5NTYWnpyfee+895OTk3PMBMrp/er0eGzduREJCAhYuXDhgP95XRs79xgTgfWUkrF69GsuXL0d1dTWys7NhNBrR2dk54A9H1nStcAuNhdjZ2aGzs7NPe88/jp5/CHfraTcajQOO5RPqD+ZBYzKQJ554Avb29jh16tSQzI++H14rtuW5554DAF4vQ6Surg7PP/88XFxc8MYbb0AqHfh2z2tlZHyfmAyE95WhFRoaiocffhhLly7Fe++9h4sXL2L9+vUD9rema4UJvIVotdp+t2TU1dUBADw8PPod5+rqCqVSKfa7e6xEIun3Vzv03R40JgORSqXw9PTEzZs3h2R+9P30xGuga0Wj0XD7jBVxd3eHQqHg9TIEbt26hVWrVuHWrVvYsWPHd94TeF8Zft83JgPhfWX4KBQKzJkzB4cPHx5wFd2arhUm8BYSFhaGsrIytLS09GrPy8sTj/dHKpUiJCQEBQUFfY7l5+fD398f9vb2Qz/hMeBBYzKQzs5OXL9+fdCVOujBeHp6Qq1WD3itTJo0yQKzooFUV1ejs7OTteAHqaOjAy+88AKuXr2Kt99+G0FBQd85hveV4fUgMRkI7yvDq729HYIg9MkDeljTtcIE3kJSUlLQ2dmJjIwMsc1oNCIzMxPx8fHiw5RVVVV9Sk3Nnz8f58+fR2FhodhWWlqK06dPIyUlZWROYBQaTEwaGhr6/H3vvfceOjo6MG3atOGdOAEArl27hmvXrvVqe+SRR3D8+HHU1NSIbadOncLVq1d5rYyQu+PS0dHRb+nIt956CwAwderUEZvbaNPV1YW1a9fi/PnzeOONNxAbG9tvP95XRs5gYsL7yvDp73vb3NyMQ4cOYfz48dBoNACs+1qRCCwsajFr1qzBsWPH8PTTT8PPzw9ZWVkoKCjABx98gISEBADAypUrcebMGRQXF4vjmpubsXjxYrS1teHZZ5+FTCZDeno6BEHAnj17+JP5IDxoTGJiYrBgwQKEhIRAqVTiyy+/xKFDh5CQkICdO3dCLufz4oPOATNYAAAGk0lEQVTRk9zp9Xrs27cPS5cuhY+PD5ydnbFixQoAwOzZswEAx48fF8ddv34dixYtgqurK1asWIHW1la89957GD9+PKs4DIEHiUtlZSUWL16M1NRUBAUFiVVoTp06hQULFuBPf/qTZU5mFPjjH/+InTt3YtasWfjhD3/Y65iDgwPmzp0LgPeVkTSYmPC+MnzS0tKgUqkQFxcHrVaL69evIzMzE9XV1di6dSsWLFgAwLqvFSbwFtTR0YFt27Zh7969uHnzJkJDQ/Hyyy8jOTlZ7NPfPx7A/OvmTZs2IScnByaTCYmJidiwYQN8fX1H+jRGlQeNyW9+8xucO3cO169fR2dnJ7y9vbFgwQI8//zzfPhrCISGhvbb7u3tLSaG/SXwAHDlyhX8+7//O86ePQuFQoGZM2di/fr13KoxBB4kLk1NTfj973+PvLw81NbWwmQyISAgAIsXL0ZaWhqfSxiEnv839efOmPC+MnIGExPeV4bP7t27kZ2djZKSEjQ1NcHJyQmxsbF47rnn8IMf/EDsZ83XChN4IiIiIiIbwj3wREREREQ2hAk8EREREZENYQJPRERERGRDmMATEREREdkQJvBERERERDaECTwRERERkQ1hAk9EREREZEOYwBMRkdVbuXKl+FIoIqKxju/hJSIao7788kukpaUNeFwmk6GwsHAEZ0RERPeDCTwR0RiXmpqK6dOn92mXSvlLWiIia8QEnohojAsPD8fChQstPQ0iIrpPXF4hIqJ7qqysRGhoKLZv3459+/bh0UcfRVRUFGbOnInt27fj9u3bfcZcunQJq1evRmJiIqKiorBgwQK8++676Orq6tO3rq4Of/jDHzBnzhxERkYiKSkJzz77LHJycvr0rampwcsvv4yHHnoIMTEx+OlPf4qysrJhOW8iImvFFXgiojGura0NDQ0NfdqVSiUcHR3Fr48fP46Kigo89dRTcHd3x/Hjx/HnP/8ZVVVV2Lx5s9jvwoULWLlyJeRyudj3xIkT2LJlCy5duoTXX39d7FtZWYknnngCBoMBCxcuRGRkJNra2pCXl4fc3Fw8/PDDYt/W1lasWLECMTExWLduHSorK7Fz5068+OKL2LdvH2Qy2TB9h4iIrAsTeCKiMW779u3Yvn17n/aZM2fi7bffFr++dOkSdu/ejYiICADAihUr8NJLLyEzMxPLly9HbGwsAOCPf/wjjEYjPv74Y4SFhYl9165di3379uGxxx5DUlISAOB3v/sdamtrsWPHDkybNq3X55tMpl5f37hxAz/96U+xatUqsU2tVuO1115Dbm5un/FERKMVE3giojFu+fLlSElJ6dOuVqt7fZ2cnCwm7wAgkUjws5/9DEePHsWRI0cQGxsLg8GAb775BvPmzROT956+v/jFL3Dw4EEcOXIESUlJaGxsxOeff45p06b1m3zf/RCtVCrtUzVnypQpAIDy8nIm8EQ0ZjCBJyIa4/z9/ZGcnPyd/XQ6XZ+24OBgAEBFRQUA85aYO9vvFBQUBKlUKva9du0aBEFAeHj4fc3Tw8MDKpWqV5urqysAoLGx8b7+DiKi0YAPsRIRkU241x53QRBGcCZERJbFBJ6IiO6LXq/v01ZSUgIA8PX1BQD4+Pj0ar9TaWkpTCaT2NfPzw8SiQRFRUXDNWUiolGJCTwREd2X3NxcXLx4UfxaEATs2LEDADB37lwAgEajQVxcHE6cOIHLly/36vvOO+8AAObNmwfAvP1l+vTpOHnyJHJzc/t8HlfViYj6xz3wRERjXGFhIbKzs/s91pOYA0BYWBiefvppPPXUU9BqtTh27Bhyc3OxcOFCxMXFif02bNiAlStX4qmnnsKTTz4JrVaLEydO4IsvvkBqaqpYgQYAfvvb36KwsBCrVq3CokWLEBERgY6ODuTl5cHb2xu/+tWvhu/EiYhsFBN4IqIxbt++fdi3b1+/xw4fPizuPZ89ezYCAwPx9ttvo6ysDBqNBi+++CJefPHFXmOioqLw8ccf480338RHH32E1tZW+Pr64p//+Z/x3HPP9err6+uLv//97/iv//ovnDx5EtnZ2XB2dkZYWBiWL18+PCdMRGTjJAJ/R0lERPdQWVmJOXPm4KWXXsI//dM/WXo6RERjHvfAExERERHZECbwREREREQ2hAk8EREREZEN4R54IiIiIiIbwhV4IiIiIiIbwgSeiIiIiMiGMIEnIiIiIrIhTOCJiIiIiGwIE3giIiIiIhvCBJ6IiIiIyIb8fzucAdL0zmf6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTqhMkixJmOn",
        "outputId": "8e11ec29-9f7e-4683-9632-83f6445f2cb0"
      },
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "df['clean_tweets'] = [re.sub('(?P<url>https?://[^\\s]+)', '', str(tweet)) for tweet in df['tweets']]\n",
        "df['clean_tweets'] = [re.sub('[^0-9 a-zA-Z@#]+', '', str(tweet)) for tweet in df['clean_tweets']]\n",
        "df['clean_tweets'] = [re.sub('@(.*?)[\\s]', '@user ', str(tweet)) for tweet in df['clean_tweets']]\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.clean_tweets.values\n",
        "labels = df.labels.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "# Start here\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 1,038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X7wcz0WJ4NX",
        "outputId": "541ed115-7c71-451e-9f3d-c50f49e34b9a"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,038 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r9KczgFJ7p2",
        "outputId": "87771279-969b-4baf-f4a9-dc3029c55ee9"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.labels.sum(), len(df.labels), (df.labels.sum() / len(df.labels) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 38 of 1038 (3.66%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PNUonv5J_a-",
        "outputId": "46512097-b48a-4bf5-ccca-9852275564eb"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGhCSFUtKC1m",
        "outputId": "fc659615-c59c-4880-e1f9-fb92a071face"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTN8MHlcLPp4"
      },
      "source": [
        "# Save and Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk1DM5zyKF3-",
        "outputId": "b58c1a09-3c23-4d90-80c4-adb65b8a4c04"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cecl1wvcLwSQ",
        "outputId": "a90e6b4b-d682-491b-cf07-45cc22c5a908"
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvYq_-eyM63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b364e6-3e18-49b4-d401-39b2ffe8c244"
      },
      "source": [
        "!zip model_save.zip model_save/*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model_save/config.json (deflated 47%)\n",
            "  adding: model_save/pytorch_model.bin (deflated 7%)\n",
            "  adding: model_save/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_save/tokenizer_config.json (deflated 37%)\n",
            "  adding: model_save/vocab.txt (deflated 53%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbDN3hpe0a_N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}