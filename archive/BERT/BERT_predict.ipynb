{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT predict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwq-s-OaxzDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec11158-06c1-487f-96ce-e71b3a3707d9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 56.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2MNkRiDSrup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40bc8b3-a974-4896-de52-aa41dc9e93cc"
      },
      "source": [
        "!unzip model_save.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  model_save.zip\n",
            "   creating: model_save/\n",
            "  inflating: model_save/config.json  \n",
            "  inflating: model_save/pytorch_model.bin  \n",
            "  inflating: model_save/special_tokens_map.json  \n",
            "  inflating: model_save/tokenizer_config.json  \n",
            "  inflating: model_save/vocab.txt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkoH6y7ekNqp"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "\n",
        "class BERT:\n",
        "    def set_device(self):\n",
        "        \"\"\"\n",
        "        Sets device as 'GPU' or 'CPU'\n",
        "        \"\"\"\n",
        "        # if there's a GPU available...\n",
        "        if torch.cuda.is_available():\n",
        "            # tell PyTorch to use the GPU.\n",
        "            device = torch.device('cuda')\n",
        "        else:\n",
        "            device = torch.device('cpu')\n",
        "\n",
        "        return device\n",
        "\n",
        "    def load_model(self, path):\n",
        "        \"\"\"\n",
        "        Loads model and tokenizer from binary file\n",
        "\n",
        "        path: str\n",
        "        \"\"\"\n",
        "        # load a trained model and vocabulary that you have fine-tuned\n",
        "        model = BertForSequenceClassification.from_pretrained(path)\n",
        "        tokenizer = BertTokenizer.from_pretrained(path)\n",
        "\n",
        "        return model, tokenizer\n",
        "\n",
        "    def predict(self, text, model_path):\n",
        "        \"\"\"\n",
        "        Uses fine tuned BERTforSequenceClassification to make a \n",
        "        prediction\n",
        "        \n",
        "        text: str\n",
        "        model_path: str\n",
        "        \"\"\"\n",
        "        device = self.set_device()\n",
        "\n",
        "        model, tokenizer = self.load_model(model_path)\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        # prepare our text into tokenized sequence\n",
        "        inputs = tokenizer(text, padding=True, truncation=True,\n",
        "                           max_length=64, return_tensors='pt').to(device)\n",
        "\n",
        "        # perform inference on our model\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        # get output probabilities through softmax\n",
        "        probs = outputs[0].softmax(1)\n",
        "        \n",
        "        # executing argmax function to get label\n",
        "        return np.argmax(probs.detach().cpu().numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKGs-h60NO4F",
        "outputId": "5161a6de-d07d-4507-fc63-0089aa430b68"
      },
      "source": [
        "bert = BERT()\n",
        "\n",
        "test = \"the police shot and killed a 15 year old Black girl in Columbus as the verdict was being read. She reportedly called them for help. this isn't a giant step anywhere\"\n",
        "\n",
        "print(bert.predict(test, '/content/model_save'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3D8auuehAJB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}