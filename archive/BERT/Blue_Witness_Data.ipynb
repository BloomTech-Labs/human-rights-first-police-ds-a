{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blue_Witness_Data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcuQJ41F8IXB"
      },
      "source": [
        "#### Mine data using [tweepy](https://gist.github.com/nickhargreaves/44615385daf335166980) to filter tweets by location, date, and keywords\n",
        "#### Use [Latent Dirichlet Allocation](https://colab.research.google.com/drive/1LZDjdgzJBaPRDLUES-50h9mi3zknEIg6?usp=sharing) (LDA) to identify the most relevent docs\n",
        "* Lemmatize Docs\n",
        "* Create Dictionary\n",
        "* Term Document Frequency for Each Doc -> Doc-Term Matrix\n",
        "* Estimate a LDA Model with Gensim\n",
        "* Measure Topic Coherence\n",
        "* Select Most Relevent Docs\n",
        "\n",
        "#### Ensure an even distribution of ranks per doc (SMOTE?)\n",
        "#### Use corpus to train BERT and secondary model (K-NN, SpaCY, RNN, etc.)\n",
        "#### Take BERT output and feed into new model to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU9pYhQm75XT"
      },
      "source": [
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "\n",
        "consumer_key= ''\n",
        "consumer_secret= ''\n",
        "access_token= ''\n",
        "access_token_secret= ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y146DxSJr__g"
      },
      "source": [
        "print('Establishing Connection to Twitter...')\n",
        "\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "print('Success!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkYa_ZEwsD2E"
      },
      "source": [
        "# Define the search term\n",
        "search_words = '#BLM -filter:retweets'\n",
        "max_tweets = 1000\n",
        "\n",
        "print('Searching...')\n",
        "\n",
        "tweets = [tweet.text for tweet in tw.Cursor(api.search, q=search_words, lang=\"en\").items(max_tweets)]\n",
        "\n",
        "tweets[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmzAe9NbsSbT"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "df = pd.DataFrame(tweets, columns=['tweets'])\n",
        "\n",
        "df.to_csv('BLM_tweets.csv')\n",
        "\n",
        "files.download('BLM_tweets.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M88k5lKS6YgH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}